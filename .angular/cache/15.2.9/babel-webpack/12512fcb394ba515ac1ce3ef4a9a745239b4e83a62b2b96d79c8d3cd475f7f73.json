{"ast":null,"code":"\"use strict\";\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.ConversationTranslatorConnectionFactory = void 0;\nconst Exports_js_1 = require(\"../../common.browser/Exports.js\");\nconst StringUtils_js_1 = require(\"../../common/StringUtils.js\");\nconst Contracts_js_1 = require(\"../../sdk/Contracts.js\");\nconst Exports_js_2 = require(\"../../sdk/Exports.js\");\nconst HeaderNames_js_1 = require(\"../HeaderNames.js\");\nconst QueryParameterNames_js_1 = require(\"../QueryParameterNames.js\");\nconst ConnectionFactoryBase_js_1 = require(\"./../ConnectionFactoryBase.js\");\nconst Exports_js_3 = require(\"./../Exports.js\");\n/**\n * Connection factory for the conversation translator. Handles connecting to the regular translator endpoint,\n * as well as the virtual microphone array transcription endpoint\n */\nclass ConversationTranslatorConnectionFactory extends ConnectionFactoryBase_js_1.ConnectionFactoryBase {\n  constructor(convGetter) {\n    super();\n    Contracts_js_1.Contracts.throwIfNullOrUndefined(convGetter, \"convGetter\");\n    this.privConvGetter = convGetter;\n  }\n  create(config, authInfo, connectionId) {\n    const isVirtMicArrayEndpoint = config.parameters.getProperty(\"ConversationTranslator_MultiChannelAudio\", \"\").toUpperCase() === \"TRUE\";\n    const convInfo = this.privConvGetter().room;\n    const region = convInfo.cognitiveSpeechRegion || config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, \"\");\n    const replacementValues = {\n      hostSuffix: ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region),\n      path: ConversationTranslatorConnectionFactory.CTS_VIRT_MIC_PATH,\n      region: encodeURIComponent(region)\n    };\n    replacementValues[QueryParameterNames_js_1.QueryParameterNames.Language] = encodeURIComponent(config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage, \"\"));\n    replacementValues[QueryParameterNames_js_1.QueryParameterNames.CtsMeetingId] = encodeURIComponent(convInfo.roomId);\n    replacementValues[QueryParameterNames_js_1.QueryParameterNames.CtsDeviceId] = encodeURIComponent(convInfo.participantId);\n    replacementValues[QueryParameterNames_js_1.QueryParameterNames.CtsIsParticipant] = convInfo.isHost ? \"\" : \"&\" + QueryParameterNames_js_1.QueryParameterNames.CtsIsParticipant;\n    let endpointUrl = \"\";\n    const queryParams = {};\n    const headers = {};\n    if (isVirtMicArrayEndpoint) {\n      // connecting to the conversation transcription virtual microphone array endpoint\n      endpointUrl = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint);\n      if (!endpointUrl) {\n        const hostName = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, \"transcribe.{region}.cts.speech{hostSuffix}\");\n        endpointUrl = \"wss://\" + hostName + \"{path}\";\n      }\n      // because the region can change during a session, we support being passed a format string which we can then\n      // replace with the correct information.\n      endpointUrl = StringUtils_js_1.StringUtils.formatString(endpointUrl, replacementValues);\n      const parsedUrl = new URL(endpointUrl);\n      parsedUrl.searchParams.forEach((val, key) => {\n        queryParams[key] = val;\n      });\n      const connFactory = new Exports_js_3.TranscriberConnectionFactory();\n      connFactory.setQueryParams(queryParams, config, endpointUrl);\n      // Some query parameters are required for the CTS endpoint, let's explicity set them here\n      queryParams[QueryParameterNames_js_1.QueryParameterNames.CtsMeetingId] = replacementValues[QueryParameterNames_js_1.QueryParameterNames.CtsMeetingId];\n      queryParams[QueryParameterNames_js_1.QueryParameterNames.CtsDeviceId] = replacementValues[QueryParameterNames_js_1.QueryParameterNames.CtsDeviceId];\n      if (!convInfo.isHost) {\n        queryParams[QueryParameterNames_js_1.QueryParameterNames.CtsIsParticipant] = \"\"; // this doesn't have a value so set to an empty string\n      }\n\n      if (!(QueryParameterNames_js_1.QueryParameterNames.Format in queryParams)) {\n        queryParams[QueryParameterNames_js_1.QueryParameterNames.Format] = \"simple\";\n      }\n      parsedUrl.searchParams.forEach((val, key) => {\n        parsedUrl.searchParams.set(key, queryParams[key]);\n        delete queryParams[key];\n      });\n      endpointUrl = parsedUrl.toString();\n    } else {\n      // connecting to regular translation endpoint\n      const connFactory = new Exports_js_3.TranslationConnectionFactory();\n      endpointUrl = connFactory.getEndpointUrl(config, true);\n      endpointUrl = StringUtils_js_1.StringUtils.formatString(endpointUrl, replacementValues);\n      connFactory.setQueryParams(queryParams, config, endpointUrl);\n    }\n    headers[HeaderNames_js_1.HeaderNames.ConnectionId] = connectionId;\n    headers[Exports_js_1.RestConfigBase.configParams.token] = convInfo.token;\n    if (!!authInfo.token) {\n      headers[authInfo.headerName] = authInfo.token;\n    }\n    const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"\").toUpperCase() === \"TRUE\";\n    return new Exports_js_1.WebsocketConnection(endpointUrl, queryParams, headers, new Exports_js_3.WebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n  }\n}\nexports.ConversationTranslatorConnectionFactory = ConversationTranslatorConnectionFactory;\nConversationTranslatorConnectionFactory.CTS_VIRT_MIC_PATH = \"/speech/recognition/dynamicaudio\";\n\n//# sourceMappingURL=ConversationTranslatorConnectionFactory.js.map","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}