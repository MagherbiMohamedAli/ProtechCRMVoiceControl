{"ast":null,"code":"\"use strict\";\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.AudioStreamFormatImpl = exports.AudioStreamFormat = exports.AudioFormatTag = void 0;\n// eslint-disable-next-line max-classes-per-file\nvar AudioFormatTag;\n(function (AudioFormatTag) {\n  AudioFormatTag[AudioFormatTag[\"PCM\"] = 1] = \"PCM\";\n  AudioFormatTag[AudioFormatTag[\"MuLaw\"] = 2] = \"MuLaw\";\n  AudioFormatTag[AudioFormatTag[\"Siren\"] = 3] = \"Siren\";\n  AudioFormatTag[AudioFormatTag[\"MP3\"] = 4] = \"MP3\";\n  AudioFormatTag[AudioFormatTag[\"SILKSkype\"] = 5] = \"SILKSkype\";\n  AudioFormatTag[AudioFormatTag[\"OGG_OPUS\"] = 6] = \"OGG_OPUS\";\n  AudioFormatTag[AudioFormatTag[\"WEBM_OPUS\"] = 7] = \"WEBM_OPUS\";\n  AudioFormatTag[AudioFormatTag[\"ALaw\"] = 8] = \"ALaw\";\n  AudioFormatTag[AudioFormatTag[\"FLAC\"] = 9] = \"FLAC\";\n  AudioFormatTag[AudioFormatTag[\"OPUS\"] = 10] = \"OPUS\";\n})(AudioFormatTag = exports.AudioFormatTag || (exports.AudioFormatTag = {}));\n/**\n * Represents audio stream format used for custom audio input configurations.\n * @class AudioStreamFormat\n */\nclass AudioStreamFormat {\n  /**\n   * Creates an audio stream format object representing the default audio stream\n   * format (16KHz 16bit mono PCM).\n   * @member AudioStreamFormat.getDefaultInputFormat\n   * @function\n   * @public\n   * @returns {AudioStreamFormat} The audio stream format being created.\n   */\n  static getDefaultInputFormat() {\n    return AudioStreamFormatImpl.getDefaultInputFormat();\n  }\n  /**\n   * Creates an audio stream format object with the specified format characteristics.\n   * @member AudioStreamFormat.getWaveFormat\n   * @function\n   * @public\n   * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).\n   * @param {number} bitsPerSample - Bits per sample, typically 16.\n   * @param {number} channels - Number of channels in the waveform-audio data. Monaural data\n   * uses one channel and stereo data uses two channels.\n   * @param {AudioFormatTag} format - Audio format (PCM, alaw or mulaw).\n   * @returns {AudioStreamFormat} The audio stream format being created.\n   */\n  static getWaveFormat(samplesPerSecond, bitsPerSample, channels, format) {\n    return new AudioStreamFormatImpl(samplesPerSecond, bitsPerSample, channels, format);\n  }\n  /**\n   * Creates an audio stream format object with the specified pcm waveformat characteristics.\n   * @member AudioStreamFormat.getWaveFormatPCM\n   * @function\n   * @public\n   * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).\n   * @param {number} bitsPerSample - Bits per sample, typically 16.\n   * @param {number} channels - Number of channels in the waveform-audio data. Monaural data\n   * uses one channel and stereo data uses two channels.\n   * @returns {AudioStreamFormat} The audio stream format being created.\n   */\n  static getWaveFormatPCM(samplesPerSecond, bitsPerSample, channels) {\n    return new AudioStreamFormatImpl(samplesPerSecond, bitsPerSample, channels);\n  }\n}\nexports.AudioStreamFormat = AudioStreamFormat;\n/**\n * @private\n * @class AudioStreamFormatImpl\n */\nclass AudioStreamFormatImpl extends AudioStreamFormat {\n  /**\n   * Creates an instance with the given values.\n   * @constructor\n   * @param {number} samplesPerSec - Samples per second.\n   * @param {number} bitsPerSample - Bits per sample.\n   * @param {number} channels - Number of channels.\n   * @param {AudioFormatTag} format - Audio format (PCM, alaw or mulaw).\n   */\n  constructor(samplesPerSec = 16000, bitsPerSample = 16, channels = 1, format = AudioFormatTag.PCM) {\n    super();\n    let isWavFormat = true;\n    /* 1 for PCM; 6 for alaw; 7 for mulaw */\n    switch (format) {\n      case AudioFormatTag.PCM:\n        this.formatTag = 1;\n        break;\n      case AudioFormatTag.ALaw:\n        this.formatTag = 6;\n        break;\n      case AudioFormatTag.MuLaw:\n        this.formatTag = 7;\n        break;\n      default:\n        isWavFormat = false;\n    }\n    this.bitsPerSample = bitsPerSample;\n    this.samplesPerSec = samplesPerSec;\n    this.channels = channels;\n    this.avgBytesPerSec = this.samplesPerSec * this.channels * (this.bitsPerSample / 8);\n    this.blockAlign = this.channels * Math.max(this.bitsPerSample, 8);\n    if (isWavFormat) {\n      this.privHeader = new ArrayBuffer(44);\n      // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView\n      const view = new DataView(this.privHeader);\n      /* RIFF identifier */\n      this.setString(view, 0, \"RIFF\");\n      /* file length */\n      view.setUint32(4, 0, true);\n      /* RIFF type & Format */\n      this.setString(view, 8, \"WAVEfmt \");\n      /* format chunk length */\n      view.setUint32(16, 16, true);\n      /* audio format */\n      view.setUint16(20, this.formatTag, true);\n      /* channel count */\n      view.setUint16(22, this.channels, true);\n      /* sample rate */\n      view.setUint32(24, this.samplesPerSec, true);\n      /* byte rate (sample rate * block align) */\n      view.setUint32(28, this.avgBytesPerSec, true);\n      /* block align (channel count * bytes per sample) */\n      view.setUint16(32, this.channels * (this.bitsPerSample / 8), true);\n      /* bits per sample */\n      view.setUint16(34, this.bitsPerSample, true);\n      /* data chunk identifier */\n      this.setString(view, 36, \"data\");\n      /* data chunk length */\n      view.setUint32(40, 0, true);\n    }\n  }\n  /**\n   * Retrieves the default input format.\n   * @member AudioStreamFormatImpl.getDefaultInputFormat\n   * @function\n   * @public\n   * @returns {AudioStreamFormatImpl} The default input format.\n   */\n  static getDefaultInputFormat() {\n    return new AudioStreamFormatImpl();\n  }\n  /**\n   * Creates an audio context appropriate to current browser\n   * @member AudioStreamFormatImpl.getAudioContext\n   * @function\n   * @public\n   * @returns {AudioContext} An audio context instance\n   */\n  /* eslint-disable */\n  static getAudioContext(sampleRate) {\n    // Workaround for Speech SDK bug in Safari.\n    const AudioContext = window.AudioContext // our preferred impl\n    || window.webkitAudioContext // fallback, mostly when on Safari\n    || false; // could not find.\n    // https://developer.mozilla.org/en-US/docs/Web/API/AudioContext\n    if (!!AudioContext) {\n      if (sampleRate !== undefined && navigator.mediaDevices.getSupportedConstraints().sampleRate) {\n        return new AudioContext({\n          sampleRate\n        });\n      } else {\n        return new AudioContext();\n      }\n    } else {\n      throw new Error(\"Browser does not support Web Audio API (AudioContext is not available).\");\n    }\n  }\n  /* eslint-enable */\n  /**\n   * Closes the configuration object.\n   * @member AudioStreamFormatImpl.prototype.close\n   * @function\n   * @public\n   */\n  close() {\n    return;\n  }\n  get header() {\n    return this.privHeader;\n  }\n  setString(view, offset, str) {\n    for (let i = 0; i < str.length; i++) {\n      view.setUint8(offset + i, str.charCodeAt(i));\n    }\n  }\n}\nexports.AudioStreamFormatImpl = AudioStreamFormatImpl;\n\n//# sourceMappingURL=AudioStreamFormat.js.map","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}