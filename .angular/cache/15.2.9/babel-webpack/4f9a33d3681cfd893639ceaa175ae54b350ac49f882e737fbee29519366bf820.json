{"ast":null,"code":"\"use strict\";\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.ServiceRecognizerBase = void 0;\nconst Exports_js_1 = require(\"../common.browser/Exports.js\");\nconst Exports_js_2 = require(\"../common/Exports.js\");\nconst Exports_js_3 = require(\"../sdk/Exports.js\");\nconst Exports_js_4 = require(\"./Exports.js\");\nconst SpeechConnectionMessage_Internal_js_1 = require(\"./SpeechConnectionMessage.Internal.js\");\nclass ServiceRecognizerBase {\n  constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {\n    // A promise for a configured connection.\n    // Do not consume directly, call fetchConnection instead.\n    this.privConnectionConfigurationPromise = undefined;\n    // A promise for a connection, but one that has not had the speech context sent yet.\n    // Do not consume directly, call fetchConnection instead.\n    this.privConnectionPromise = undefined;\n    this.privSetTimeout = setTimeout;\n    this.privIsLiveAudio = false;\n    this.privAverageBytesPerMs = 0;\n    this.privEnableSpeakerId = false;\n    this.privExpectContentAssessmentResponse = false;\n    this.recognizeOverride = undefined;\n    this.recognizeSpeaker = undefined;\n    this.disconnectOverride = undefined;\n    this.receiveMessageOverride = undefined;\n    this.sendPrePayloadJSONOverride = undefined;\n    this.postConnectImplOverride = undefined;\n    this.configConnectionOverride = undefined;\n    this.handleSpeechPhraseMessage = undefined;\n    this.handleSpeechHypothesisMessage = undefined;\n    if (!authentication) {\n      throw new Exports_js_2.ArgumentNullError(\"authentication\");\n    }\n    if (!connectionFactory) {\n      throw new Exports_js_2.ArgumentNullError(\"connectionFactory\");\n    }\n    if (!audioSource) {\n      throw new Exports_js_2.ArgumentNullError(\"audioSource\");\n    }\n    if (!recognizerConfig) {\n      throw new Exports_js_2.ArgumentNullError(\"recognizerConfig\");\n    }\n    this.privEnableSpeakerId = recognizerConfig.isSpeakerDiarizationEnabled;\n    this.privMustReportEndOfStream = false;\n    this.privAuthentication = authentication;\n    this.privConnectionFactory = connectionFactory;\n    this.privAudioSource = audioSource;\n    this.privRecognizerConfig = recognizerConfig;\n    this.privIsDisposed = false;\n    this.privRecognizer = recognizer;\n    this.privRequestSession = new Exports_js_4.RequestSession(this.privAudioSource.id());\n    this.privConnectionEvents = new Exports_js_2.EventSource();\n    this.privServiceEvents = new Exports_js_2.EventSource();\n    this.privDynamicGrammar = new Exports_js_4.DynamicGrammarBuilder();\n    this.privSpeechContext = new Exports_js_4.SpeechContext(this.privDynamicGrammar);\n    this.privAgentConfig = new Exports_js_4.AgentConfig();\n    const webWorkerLoadType = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.WebWorkerLoadType, \"on\").toLowerCase();\n    if (webWorkerLoadType === \"on\" && typeof Blob !== \"undefined\" && typeof Worker !== \"undefined\") {\n      this.privSetTimeout = Exports_js_2.Timeout.setTimeout;\n    } else {\n      if (typeof window !== \"undefined\") {\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n        this.privSetTimeout = window.setTimeout.bind(window);\n      }\n    }\n    this.connectionEvents.attach(connectionEvent => {\n      if (connectionEvent.name === \"ConnectionClosedEvent\") {\n        const connectionClosedEvent = connectionEvent;\n        if (connectionClosedEvent.statusCode === 1003 || connectionClosedEvent.statusCode === 1007 || connectionClosedEvent.statusCode === 1002 || connectionClosedEvent.statusCode === 4000 || this.privRequestSession.numConnectionAttempts > this.privRecognizerConfig.maxRetryCount) {\n          void this.cancelRecognitionLocal(Exports_js_3.CancellationReason.Error, connectionClosedEvent.statusCode === 1007 ? Exports_js_3.CancellationErrorCode.BadRequestParameters : Exports_js_3.CancellationErrorCode.ConnectionFailure, `${connectionClosedEvent.reason} websocket error code: ${connectionClosedEvent.statusCode}`);\n        }\n      }\n    });\n    if (this.privEnableSpeakerId) {\n      this.privDiarizationSessionId = Exports_js_2.createNoDashGuid();\n    }\n    this.setLanguageIdJson();\n    this.setOutputDetailLevelJson();\n  }\n  setTranslationJson() {\n    const targetLanguages = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined);\n    if (targetLanguages !== undefined) {\n      const languages = targetLanguages.split(\",\");\n      const translationVoice = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationVoice, undefined);\n      const action = translationVoice !== undefined ? \"Synthesize\" : \"None\";\n      this.privSpeechContext.setSection(\"translation\", {\n        onSuccess: {\n          action\n        },\n        output: {\n          interimResults: {\n            mode: \"Always\"\n          }\n        },\n        targetLanguages: languages\n      });\n      if (translationVoice !== undefined) {\n        const languageToVoiceMap = {};\n        for (const lang of languages) {\n          languageToVoiceMap[lang] = translationVoice;\n        }\n        this.privSpeechContext.setSection(\"synthesis\", {\n          defaultVoices: languageToVoiceMap\n        });\n      }\n    }\n  }\n  setSpeechSegmentationTimeoutJson() {\n    const speechSegmentationTimeout = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.Speech_SegmentationSilenceTimeoutMs, undefined);\n    if (speechSegmentationTimeout !== undefined) {\n      const mode = this.recognitionMode === Exports_js_4.RecognitionMode.Conversation ? \"CONVERSATION\" : this.recognitionMode === Exports_js_4.RecognitionMode.Dictation ? \"DICTATION\" : \"INTERACTIVE\";\n      const segmentationSilenceTimeoutMs = parseInt(speechSegmentationTimeout, 10);\n      const phraseDetection = this.privSpeechContext.getSection(\"phraseDetection\");\n      phraseDetection.mode = mode;\n      phraseDetection[mode] = {\n        segmentation: {\n          mode: \"Custom\",\n          segmentationSilenceTimeoutMs\n        }\n      };\n      this.privSpeechContext.setSection(\"phraseDetection\", phraseDetection);\n    }\n  }\n  setLanguageIdJson() {\n    const phraseDetection = this.privSpeechContext.getSection(\"phraseDetection\");\n    if (this.privRecognizerConfig.autoDetectSourceLanguages !== undefined) {\n      const sourceLanguages = this.privRecognizerConfig.autoDetectSourceLanguages.split(\",\");\n      let speechContextLidMode;\n      if (this.privRecognizerConfig.languageIdMode === \"Continuous\") {\n        speechContextLidMode = \"DetectContinuous\";\n      } else {\n        // recognizerConfig.languageIdMode === \"AtStart\"\n        speechContextLidMode = \"DetectAtAudioStart\";\n      }\n      this.privSpeechContext.setSection(\"languageId\", {\n        Priority: \"PrioritizeLatency\",\n        languages: sourceLanguages,\n        mode: speechContextLidMode,\n        onSuccess: {\n          action: \"Recognize\"\n        },\n        onUnknown: {\n          action: \"None\"\n        }\n      });\n      this.privSpeechContext.setSection(\"phraseOutput\", {\n        interimResults: {\n          resultType: \"Auto\"\n        },\n        phraseResults: {\n          resultType: \"Always\"\n        }\n      });\n      const customModels = this.privRecognizerConfig.sourceLanguageModels;\n      if (customModels !== undefined) {\n        phraseDetection.customModels = customModels;\n        phraseDetection.onInterim = {\n          action: \"None\"\n        };\n        phraseDetection.onSuccess = {\n          action: \"None\"\n        };\n      }\n    }\n    const targetLanguages = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined);\n    if (targetLanguages !== undefined) {\n      phraseDetection.onInterim = {\n        action: \"Translate\"\n      };\n      phraseDetection.onSuccess = {\n        action: \"Translate\"\n      };\n      this.privSpeechContext.setSection(\"phraseOutput\", {\n        interimResults: {\n          resultType: \"None\"\n        },\n        phraseResults: {\n          resultType: \"None\"\n        }\n      });\n    }\n    this.privSpeechContext.setSection(\"phraseDetection\", phraseDetection);\n  }\n  setOutputDetailLevelJson() {\n    if (this.privEnableSpeakerId) {\n      const requestWordLevelTimestamps = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, \"false\").toLowerCase();\n      if (requestWordLevelTimestamps === \"true\") {\n        this.privSpeechContext.setWordLevelTimings();\n      } else {\n        const outputFormat = this.privRecognizerConfig.parameters.getProperty(Exports_js_4.OutputFormatPropertyName, Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Simple]).toLowerCase();\n        if (outputFormat === Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Detailed].toLocaleLowerCase()) {\n          this.privSpeechContext.setDetailedOutputFormat();\n        }\n      }\n    }\n  }\n  get isSpeakerDiarizationEnabled() {\n    return this.privEnableSpeakerId;\n  }\n  get audioSource() {\n    return this.privAudioSource;\n  }\n  get speechContext() {\n    return this.privSpeechContext;\n  }\n  get dynamicGrammar() {\n    return this.privDynamicGrammar;\n  }\n  get agentConfig() {\n    return this.privAgentConfig;\n  }\n  set conversationTranslatorToken(token) {\n    this.privRecognizerConfig.parameters.setProperty(Exports_js_3.PropertyId.ConversationTranslator_Token, token);\n  }\n  set voiceProfileType(type) {\n    this.privRecognizerConfig.parameters.setProperty(Exports_js_3.PropertyId.SpeechServiceConnection_SpeakerIdMode, type);\n  }\n  set authentication(auth) {\n    this.privAuthentication = auth;\n  }\n  isDisposed() {\n    return this.privIsDisposed;\n  }\n  dispose(reason) {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.privIsDisposed = true;\n      if (this.privConnectionConfigurationPromise !== undefined) {\n        try {\n          const connection = yield this.privConnectionConfigurationPromise;\n          yield connection.dispose(reason);\n        } catch (error) {\n          // The connection is in a bad state. But we're trying to kill it, so...\n          return;\n        }\n      }\n    });\n  }\n  get connectionEvents() {\n    return this.privConnectionEvents;\n  }\n  get serviceEvents() {\n    return this.privServiceEvents;\n  }\n  get recognitionMode() {\n    return this.privRecognizerConfig.recognitionMode;\n  }\n  recognize(recoMode, successCallback, errorCallBack) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.recognizeOverride !== undefined) {\n        yield this.recognizeOverride(recoMode, successCallback, errorCallBack);\n        return;\n      }\n      // Clear the existing configuration promise to force a re-transmission of config and context.\n      this.privConnectionConfigurationPromise = undefined;\n      this.privRecognizerConfig.recognitionMode = recoMode;\n      this.setSpeechSegmentationTimeoutJson();\n      this.setTranslationJson();\n      this.privSuccessCallback = successCallback;\n      this.privErrorCallback = errorCallBack;\n      this.privRequestSession.startNewRecognition();\n      this.privRequestSession.listenForServiceTelemetry(this.privAudioSource.events);\n      // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().\n      const conPromise = this.connectImpl();\n      let audioNode;\n      try {\n        const audioStreamNode = yield this.audioSource.attach(this.privRequestSession.audioNodeId);\n        const format = yield this.audioSource.format;\n        const deviceInfo = yield this.audioSource.deviceInfo;\n        this.privIsLiveAudio = deviceInfo.type && deviceInfo.type === Exports_js_4.type.Microphones;\n        audioNode = new Exports_js_1.ReplayableAudioNode(audioStreamNode, format.avgBytesPerSec);\n        yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);\n        this.privRecognizerConfig.SpeechServiceConfig.Context.audio = {\n          source: deviceInfo\n        };\n      } catch (error) {\n        yield this.privRequestSession.onStopRecognizing();\n        throw error;\n      }\n      try {\n        yield conPromise;\n      } catch (error) {\n        yield this.cancelRecognitionLocal(Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.ConnectionFailure, error);\n        return;\n      }\n      const sessionStartEventArgs = new Exports_js_3.SessionEventArgs(this.privRequestSession.sessionId);\n      if (!!this.privRecognizer.sessionStarted) {\n        this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);\n      }\n      void this.receiveMessage();\n      const audioSendPromise = this.sendAudio(audioNode);\n      audioSendPromise.catch(error => __awaiter(this, void 0, void 0, function* () {\n        yield this.cancelRecognitionLocal(Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.RuntimeError, error);\n      }));\n      return;\n    });\n  }\n  stopRecognizing() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privRequestSession.isRecognizing) {\n        try {\n          yield this.audioSource.turnOff();\n          yield this.sendFinalAudio();\n          yield this.privRequestSession.onStopRecognizing();\n          yield this.privRequestSession.turnCompletionPromise;\n        } finally {\n          yield this.privRequestSession.dispose();\n        }\n      }\n      return;\n    });\n  }\n  connect() {\n    return __awaiter(this, void 0, void 0, function* () {\n      yield this.connectImpl();\n      return Promise.resolve();\n    });\n  }\n  connectAsync(cb, err) {\n    this.connectImpl().then(() => {\n      try {\n        if (!!cb) {\n          cb();\n        }\n      } catch (e) {\n        if (!!err) {\n          err(e);\n        }\n      }\n    }, reason => {\n      try {\n        if (!!err) {\n          err(reason);\n        }\n        /* eslint-disable no-empty */\n      } catch (error) {}\n    });\n  }\n  disconnect() {\n    return __awaiter(this, void 0, void 0, function* () {\n      yield this.cancelRecognitionLocal(Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.NoError, \"Disconnecting\");\n      if (this.disconnectOverride !== undefined) {\n        yield this.disconnectOverride();\n      }\n      if (this.privConnectionPromise !== undefined) {\n        try {\n          yield (yield this.privConnectionPromise).dispose();\n        } catch (error) {}\n      }\n      this.privConnectionPromise = undefined;\n    });\n  }\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  sendMessage(message) {\n    return;\n  }\n  sendNetworkMessage(path, payload) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const type = typeof payload === \"string\" ? Exports_js_2.MessageType.Text : Exports_js_2.MessageType.Binary;\n      const contentType = typeof payload === \"string\" ? \"application/json\" : \"\";\n      const connection = yield this.fetchConnection();\n      return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(type, path, this.privRequestSession.requestId, contentType, payload));\n    });\n  }\n  set activityTemplate(messagePayload) {\n    this.privActivityTemplate = messagePayload;\n  }\n  get activityTemplate() {\n    return this.privActivityTemplate;\n  }\n  set expectContentAssessmentResponse(value) {\n    this.privExpectContentAssessmentResponse = value;\n  }\n  sendTelemetryData() {\n    return __awaiter(this, void 0, void 0, function* () {\n      const telemetryData = this.privRequestSession.getTelemetry();\n      if (ServiceRecognizerBase.telemetryDataEnabled !== true || this.privIsDisposed || null === telemetryData) {\n        return;\n      }\n      if (!!ServiceRecognizerBase.telemetryData) {\n        try {\n          ServiceRecognizerBase.telemetryData(telemetryData);\n          /* eslint-disable no-empty */\n        } catch (_a) {}\n      }\n      const connection = yield this.fetchConnection();\n      yield connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, \"telemetry\", this.privRequestSession.requestId, \"application/json\", telemetryData));\n    });\n  }\n  // Cancels recognition.\n  cancelRecognitionLocal(cancellationReason, errorCode, error) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!!this.privRequestSession.isRecognizing) {\n        yield this.privRequestSession.onStopRecognizing();\n        this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, cancellationReason, errorCode, error);\n      }\n    });\n  }\n  receiveMessage() {\n    return __awaiter(this, void 0, void 0, function* () {\n      try {\n        if (this.privIsDisposed) {\n          // We're done.\n          return;\n        }\n        let connection = yield this.fetchConnection();\n        const message = yield connection.read();\n        if (this.receiveMessageOverride !== undefined) {\n          return this.receiveMessageOverride();\n        }\n        // indicates we are draining the queue and it came with no message;\n        if (!message) {\n          return this.receiveMessage();\n        }\n        this.privServiceHasSentMessage = true;\n        const connectionMessage = SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage.fromConnectionMessage(message);\n        if (connectionMessage.requestId.toLowerCase() === this.privRequestSession.requestId.toLowerCase()) {\n          switch (connectionMessage.path.toLowerCase()) {\n            case \"turn.start\":\n              this.privMustReportEndOfStream = true;\n              this.privRequestSession.onServiceTurnStartResponse();\n              break;\n            case \"speech.startdetected\":\n              const speechStartDetected = Exports_js_4.SpeechDetected.fromJSON(connectionMessage.textBody);\n              const speechStartEventArgs = new Exports_js_3.RecognitionEventArgs(speechStartDetected.Offset, this.privRequestSession.sessionId);\n              if (!!this.privRecognizer.speechStartDetected) {\n                this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);\n              }\n              break;\n            case \"speech.enddetected\":\n              let json;\n              if (connectionMessage.textBody.length > 0) {\n                json = connectionMessage.textBody;\n              } else {\n                // If the request was empty, the JSON returned is empty.\n                json = \"{ Offset: 0 }\";\n              }\n              const speechStopDetected = Exports_js_4.SpeechDetected.fromJSON(json);\n              const speechStopEventArgs = new Exports_js_3.RecognitionEventArgs(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);\n              if (!!this.privRecognizer.speechEndDetected) {\n                this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);\n              }\n              break;\n            case \"turn.end\":\n              yield this.sendTelemetryData();\n              if (this.privRequestSession.isSpeechEnded && this.privMustReportEndOfStream) {\n                this.privMustReportEndOfStream = false;\n                yield this.cancelRecognitionLocal(Exports_js_3.CancellationReason.EndOfStream, Exports_js_3.CancellationErrorCode.NoError, undefined);\n              }\n              const sessionStopEventArgs = new Exports_js_3.SessionEventArgs(this.privRequestSession.sessionId);\n              yield this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition);\n              if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {\n                if (!!this.privRecognizer.sessionStopped) {\n                  this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);\n                }\n                return;\n              } else {\n                connection = yield this.fetchConnection();\n                yield this.sendPrePayloadJSON(connection);\n              }\n              break;\n            default:\n              if (!(yield this.processTypeSpecificMessages(connectionMessage))) {\n                // here are some messages that the derived class has not processed, dispatch them to connect class\n                if (!!this.privServiceEvents) {\n                  this.serviceEvents.onEvent(new Exports_js_2.ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));\n                }\n              }\n          }\n        }\n        return this.receiveMessage();\n      } catch (error) {\n        return null;\n      }\n    });\n  }\n  updateSpeakerDiarizationAudioOffset() {\n    const bytesSent = this.privRequestSession.recognitionBytesSent;\n    const audioOffsetMs = bytesSent / this.privAverageBytesPerMs;\n    this.privSpeechContext.setSpeakerDiarizationAudioOffsetMs(audioOffsetMs);\n  }\n  sendSpeechContext(connection, generateNewRequestId) {\n    if (this.privEnableSpeakerId) {\n      this.updateSpeakerDiarizationAudioOffset();\n    }\n    const speechContextJson = this.speechContext.toJSON();\n    if (generateNewRequestId) {\n      this.privRequestSession.onSpeechContext();\n    }\n    if (speechContextJson) {\n      return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, \"speech.context\", this.privRequestSession.requestId, \"application/json\", speechContextJson));\n    }\n    return;\n  }\n  noOp() {\n    // operation not supported\n    return;\n  }\n  // Encapsulated for derived service recognizers that need to send additional JSON\n  sendPrePayloadJSON(connection, generateNewRequestId = true) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.sendPrePayloadJSONOverride !== undefined) {\n        return this.sendPrePayloadJSONOverride(connection);\n      }\n      yield this.sendSpeechContext(connection, generateNewRequestId);\n      yield this.sendWaveHeader(connection);\n      return;\n    });\n  }\n  sendWaveHeader(connection) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const format = yield this.audioSource.format;\n      // this.writeBufferToConsole(format.header);\n      return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Binary, \"audio\", this.privRequestSession.requestId, \"audio/x-wav\", format.header));\n    });\n  }\n  // Establishes a websocket connection to the end point.\n  connectImpl() {\n    if (this.privConnectionPromise !== undefined) {\n      return this.privConnectionPromise.then(connection => {\n        if (connection.state() === Exports_js_2.ConnectionState.Disconnected) {\n          this.privConnectionId = null;\n          this.privConnectionPromise = undefined;\n          this.privServiceHasSentMessage = false;\n          return this.connectImpl();\n        }\n        return this.privConnectionPromise;\n      }, () => {\n        this.privConnectionId = null;\n        this.privConnectionPromise = undefined;\n        this.privServiceHasSentMessage = false;\n        return this.connectImpl();\n      });\n    }\n    this.privConnectionPromise = this.retryableConnect();\n    // Attach an empty handler to allow the promise to run in the background while\n    // other startup events happen. It'll eventually be awaited on.\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    this.privConnectionPromise.catch(() => {});\n    if (this.postConnectImplOverride !== undefined) {\n      return this.postConnectImplOverride(this.privConnectionPromise);\n    }\n    return this.privConnectionPromise;\n  }\n  sendSpeechServiceConfig(connection, requestSession, SpeechServiceConfigJson) {\n    requestSession.onSpeechContext();\n    // filter out anything that is not required for the service to work.\n    if (ServiceRecognizerBase.telemetryDataEnabled !== true) {\n      const withTelemetry = JSON.parse(SpeechServiceConfigJson);\n      const replacement = {\n        context: {\n          system: withTelemetry.context.system\n        }\n      };\n      SpeechServiceConfigJson = JSON.stringify(replacement);\n    }\n    if (this.privRecognizerConfig.parameters.getProperty(\"f0f5debc-f8c9-4892-ac4b-90a7ab359fd2\", \"false\").toLowerCase() === \"true\") {\n      const json = JSON.parse(SpeechServiceConfigJson);\n      json.context.DisableReferenceChannel = \"True\";\n      json.context.MicSpec = \"1_0_0\";\n      SpeechServiceConfigJson = JSON.stringify(json);\n    }\n    if (SpeechServiceConfigJson) {\n      return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, \"speech.config\", requestSession.requestId, \"application/json\", SpeechServiceConfigJson));\n    }\n    return;\n  }\n  fetchConnection() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privConnectionConfigurationPromise !== undefined) {\n        return this.privConnectionConfigurationPromise.then(connection => {\n          if (connection.state() === Exports_js_2.ConnectionState.Disconnected) {\n            this.privConnectionId = null;\n            this.privConnectionConfigurationPromise = undefined;\n            this.privServiceHasSentMessage = false;\n            return this.fetchConnection();\n          }\n          return this.privConnectionConfigurationPromise;\n        }, () => {\n          this.privConnectionId = null;\n          this.privConnectionConfigurationPromise = undefined;\n          this.privServiceHasSentMessage = false;\n          return this.fetchConnection();\n        });\n      }\n      this.privConnectionConfigurationPromise = this.configureConnection();\n      return yield this.privConnectionConfigurationPromise;\n    });\n  }\n  sendAudio(audioStreamNode) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const audioFormat = yield this.audioSource.format;\n      this.privAverageBytesPerMs = audioFormat.avgBytesPerSec / 1000;\n      // The time we last sent data to the service.\n      let nextSendTime = Date.now();\n      // Max amount to send before we start to throttle\n      const fastLaneSizeMs = this.privRecognizerConfig.parameters.getProperty(\"SPEECH-TransmitLengthBeforThrottleMs\", \"5000\");\n      const maxSendUnthrottledBytes = audioFormat.avgBytesPerSec / 1000 * parseInt(fastLaneSizeMs, 10);\n      const startRecogNumber = this.privRequestSession.recogNumber;\n      const readAndUploadCycle = () => __awaiter(this, void 0, void 0, function* () {\n        // If speech is done, stop sending audio.\n        if (!this.privIsDisposed && !this.privRequestSession.isSpeechEnded && this.privRequestSession.isRecognizing && this.privRequestSession.recogNumber === startRecogNumber) {\n          const connection = yield this.fetchConnection();\n          const audioStreamChunk = yield audioStreamNode.read();\n          // we have a new audio chunk to upload.\n          if (this.privRequestSession.isSpeechEnded) {\n            // If service already recognized audio end then don't send any more audio\n            return;\n          }\n          let payload;\n          let sendDelay;\n          if (!audioStreamChunk || audioStreamChunk.isEnd) {\n            payload = null;\n            sendDelay = 0;\n          } else {\n            payload = audioStreamChunk.buffer;\n            this.privRequestSession.onAudioSent(payload.byteLength);\n            if (maxSendUnthrottledBytes >= this.privRequestSession.bytesSent) {\n              sendDelay = 0;\n            } else {\n              sendDelay = Math.max(0, nextSendTime - Date.now());\n            }\n          }\n          if (0 !== sendDelay) {\n            yield this.delay(sendDelay);\n          }\n          if (payload !== null) {\n            nextSendTime = Date.now() + payload.byteLength * 1000 / (audioFormat.avgBytesPerSec * 2);\n          }\n          // Are we still alive?\n          if (!this.privIsDisposed && !this.privRequestSession.isSpeechEnded && this.privRequestSession.isRecognizing && this.privRequestSession.recogNumber === startRecogNumber) {\n            connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Binary, \"audio\", this.privRequestSession.requestId, null, payload)).catch(() => {\n              // eslint-disable-next-line @typescript-eslint/no-empty-function\n              this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition).catch(() => {});\n            });\n            if (!(audioStreamChunk === null || audioStreamChunk === void 0 ? void 0 : audioStreamChunk.isEnd)) {\n              // this.writeBufferToConsole(payload);\n              // Regardless of success or failure, schedule the next upload.\n              // If the underlying connection was broken, the next cycle will\n              // get a new connection and re-transmit missing audio automatically.\n              return readAndUploadCycle();\n            } else {\n              // the audio stream has been closed, no need to schedule next\n              // read-upload cycle.\n              if (!this.privIsLiveAudio) {\n                this.privRequestSession.onSpeechEnded();\n              }\n            }\n          }\n        }\n      });\n      return readAndUploadCycle();\n    });\n  }\n  retryableConnect() {\n    return __awaiter(this, void 0, void 0, function* () {\n      let isUnAuthorized = false;\n      this.privAuthFetchEventId = Exports_js_2.createNoDashGuid();\n      const sessionId = this.privRequestSession.sessionId;\n      this.privConnectionId = sessionId !== undefined ? sessionId : Exports_js_2.createNoDashGuid();\n      this.privRequestSession.onPreConnectionStart(this.privAuthFetchEventId, this.privConnectionId);\n      let lastStatusCode = 0;\n      let lastReason = \"\";\n      while (this.privRequestSession.numConnectionAttempts <= this.privRecognizerConfig.maxRetryCount) {\n        // Get the auth information for the connection. This is a bit of overkill for the current API surface, but leaving the plumbing in place to be able to raise a developer-customer\n        // facing event when a connection fails to let them try and provide new auth information.\n        const authPromise = isUnAuthorized ? this.privAuthentication.fetchOnExpiry(this.privAuthFetchEventId) : this.privAuthentication.fetch(this.privAuthFetchEventId);\n        const auth = yield authPromise;\n        yield this.privRequestSession.onAuthCompleted(false);\n        // Create the connection\n        const connection = this.privConnectionFactory.create(this.privRecognizerConfig, auth, this.privConnectionId);\n        // Attach the telemetry handlers.\n        this.privRequestSession.listenForServiceTelemetry(connection.events);\n        // Attach to the underlying event. No need to hold onto the detach pointers as in the event the connection goes away,\n        // it'll stop sending events.\n        connection.events.attach(event => {\n          this.connectionEvents.onEvent(event);\n        });\n        const response = yield connection.open();\n        // 200 == everything is fine.\n        if (response.statusCode === 200) {\n          yield this.privRequestSession.onConnectionEstablishCompleted(response.statusCode);\n          return Promise.resolve(connection);\n        } else if (response.statusCode === 1006) {\n          isUnAuthorized = true;\n        }\n        lastStatusCode = response.statusCode;\n        lastReason = response.reason;\n        this.privRequestSession.onRetryConnection();\n      }\n      yield this.privRequestSession.onConnectionEstablishCompleted(lastStatusCode, lastReason);\n      return Promise.reject(`Unable to contact server. StatusCode: ${lastStatusCode}, ${this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Endpoint)} Reason: ${lastReason}`);\n    });\n  }\n  delay(delayMs) {\n    return new Promise(resolve => this.privSetTimeout(resolve, delayMs));\n  }\n  writeBufferToConsole(buffer) {\n    let out = \"Buffer Size: \";\n    if (null === buffer) {\n      out += \"null\";\n    } else {\n      const readView = new Uint8Array(buffer);\n      out += `${buffer.byteLength}\\r\\n`;\n      for (let i = 0; i < buffer.byteLength; i++) {\n        out += readView[i].toString(16).padStart(2, \"0\") + \" \";\n        if ((i + 1) % 16 === 0) {\n          // eslint-disable-next-line no-console\n          console.info(out);\n          out = \"\";\n        }\n      }\n    }\n    // eslint-disable-next-line no-console\n    console.info(out);\n  }\n  sendFinalAudio() {\n    return __awaiter(this, void 0, void 0, function* () {\n      const connection = yield this.fetchConnection();\n      yield connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Binary, \"audio\", this.privRequestSession.requestId, null, null));\n      return;\n    });\n  }\n  // Takes an established websocket connection to the endpoint and sends speech configuration information.\n  configureConnection() {\n    return __awaiter(this, void 0, void 0, function* () {\n      const connection = yield this.connectImpl();\n      if (this.configConnectionOverride !== undefined) {\n        return this.configConnectionOverride(connection);\n      }\n      yield this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());\n      yield this.sendPrePayloadJSON(connection, false);\n      return connection;\n    });\n  }\n}\nexports.ServiceRecognizerBase = ServiceRecognizerBase;\nServiceRecognizerBase.telemetryDataEnabled = true;\n\n//# sourceMappingURL=ServiceRecognizerBase.js.map","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}