{"ast":null,"code":"\"use strict\";\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.PropertyId = void 0;\n/**\n * Defines speech property ids.\n * @class PropertyId\n */\nvar PropertyId;\n(function (PropertyId) {\n  /**\n   * The Cognitive Services Speech Service subscription Key. If you are using an intent recognizer, you need to\n   * specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't\n   * have to use this property directly.\n   * Instead, use [[SpeechConfig.fromSubscription]].\n   * @member PropertyId.SpeechServiceConnection_Key\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_Key\"] = 0] = \"SpeechServiceConnection_Key\";\n  /**\n   * The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't\n   * have to use this property directly.\n   * Instead, use [[SpeechConfig.fromEndpoint]].\n   * NOTE: This endpoint is not the same as the endpoint used to obtain an access token.\n   * @member PropertyId.SpeechServiceConnection_Endpoint\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_Endpoint\"] = 1] = \"SpeechServiceConnection_Endpoint\";\n  /**\n   * The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to\n   * use this property directly.\n   * Instead, use [[SpeechConfig.fromSubscription]], [[SpeechConfig.fromEndpoint]], [[SpeechConfig.fromAuthorizationToken]].\n   * @member PropertyId.SpeechServiceConnection_Region\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_Region\"] = 2] = \"SpeechServiceConnection_Region\";\n  /**\n   * The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances,\n   * you shouldn't have to use this property directly.\n   * Instead, use [[SpeechConfig.fromAuthorizationToken]], [[SpeechRecognizer.authorizationToken]],\n   * [[IntentRecognizer.authorizationToken]], [[TranslationRecognizer.authorizationToken]], [[SpeakerRecognizer.authorizationToken]].\n   * @member PropertyId.SpeechServiceAuthorization_Token\n   */\n  PropertyId[PropertyId[\"SpeechServiceAuthorization_Token\"] = 3] = \"SpeechServiceAuthorization_Token\";\n  /**\n   * The Cognitive Services Speech Service authorization type. Currently unused.\n   * @member PropertyId.SpeechServiceAuthorization_Type\n   */\n  PropertyId[PropertyId[\"SpeechServiceAuthorization_Type\"] = 4] = \"SpeechServiceAuthorization_Type\";\n  /**\n   * The Cognitive Services Speech Service endpoint id. Under normal circumstances, you shouldn't\n   * have to use this property directly.\n   * Instead, use [[SpeechConfig.endpointId]].\n   * NOTE: The endpoint id is available in the Speech Portal, listed under Endpoint Details.\n   * @member PropertyId.SpeechServiceConnection_EndpointId\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_EndpointId\"] = 5] = \"SpeechServiceConnection_EndpointId\";\n  /**\n   * The list of comma separated languages (BCP-47 format) used as target translation languages. Under normal circumstances,\n   * you shouldn't have to use this property directly.\n   * Instead use [[SpeechTranslationConfig.addTargetLanguage]],\n   * [[SpeechTranslationConfig.targetLanguages]], [[TranslationRecognizer.targetLanguages]].\n   * @member PropertyId.SpeechServiceConnection_TranslationToLanguages\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_TranslationToLanguages\"] = 6] = \"SpeechServiceConnection_TranslationToLanguages\";\n  /**\n   * The name of the Cognitive Service Text to Speech Service Voice. Under normal circumstances, you shouldn't have to use this\n   * property directly.\n   * Instead, use [[SpeechTranslationConfig.voiceName]].\n   * NOTE: Valid voice names can be found <a href=\"https://aka.ms/csspeech/voicenames\">here</a>.\n   * @member PropertyId.SpeechServiceConnection_TranslationVoice\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_TranslationVoice\"] = 7] = \"SpeechServiceConnection_TranslationVoice\";\n  /**\n   * Translation features.\n   * @member PropertyId.SpeechServiceConnection_TranslationFeatures\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_TranslationFeatures\"] = 8] = \"SpeechServiceConnection_TranslationFeatures\";\n  /**\n   * The Language Understanding Service Region. Under normal circumstances, you shouldn't have to use this property directly.\n   * Instead, use [[LanguageUnderstandingModel]].\n   * @member PropertyId.SpeechServiceConnection_IntentRegion\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_IntentRegion\"] = 9] = \"SpeechServiceConnection_IntentRegion\";\n  /**\n   * The host name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n   * You shouldn't have to use this property directly.\n   * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n   * Added in version 1.4.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_ProxyHostName\"] = 10] = \"SpeechServiceConnection_ProxyHostName\";\n  /**\n   * The port of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n   * You shouldn't have to use this property directly.\n   * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n   * Added in version 1.4.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_ProxyPort\"] = 11] = \"SpeechServiceConnection_ProxyPort\";\n  /**\n   * The user name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n   * You shouldn't have to use this property directly.\n   * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n   * Added in version 1.4.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_ProxyUserName\"] = 12] = \"SpeechServiceConnection_ProxyUserName\";\n  /**\n   * The password of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n   * You shouldn't have to use this property directly.\n   * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n   * Added in version 1.4.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_ProxyPassword\"] = 13] = \"SpeechServiceConnection_ProxyPassword\";\n  /**\n   * The Cognitive Services Speech Service recognition Mode. Can be \"INTERACTIVE\", \"CONVERSATION\", \"DICTATION\".\n   * This property is intended to be read-only. The SDK is using it internally.\n   * @member PropertyId.SpeechServiceConnection_RecoMode\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_RecoMode\"] = 14] = \"SpeechServiceConnection_RecoMode\";\n  /**\n   * The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property\n   * directly.\n   * Instead, use [[SpeechConfig.speechRecognitionLanguage]].\n   * @member PropertyId.SpeechServiceConnection_RecoLanguage\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_RecoLanguage\"] = 15] = \"SpeechServiceConnection_RecoLanguage\";\n  /**\n   * The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream\n   * and the underlying speech recognition instance to which it is bound. Under normal circumstances, you shouldn't have to use this\n   * property directly.\n   * Instead use [[SessionEventArgs.sessionId]].\n   * @member PropertyId.Speech_SessionId\n   */\n  PropertyId[PropertyId[\"Speech_SessionId\"] = 16] = \"Speech_SessionId\";\n  /**\n   * The spoken language to be synthesized (e.g. en-US)\n   * @member PropertyId.SpeechServiceConnection_SynthLanguage\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_SynthLanguage\"] = 17] = \"SpeechServiceConnection_SynthLanguage\";\n  /**\n   * The name of the TTS voice to be used for speech synthesis\n   * @member PropertyId.SpeechServiceConnection_SynthVoice\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_SynthVoice\"] = 18] = \"SpeechServiceConnection_SynthVoice\";\n  /**\n   * The string to specify TTS output audio format\n   * @member PropertyId.SpeechServiceConnection_SynthOutputFormat\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_SynthOutputFormat\"] = 19] = \"SpeechServiceConnection_SynthOutputFormat\";\n  /**\n   * The list of comma separated languages used as possible source languages\n   * Added in version 1.13.0\n   * @member PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_AutoDetectSourceLanguages\"] = 20] = \"SpeechServiceConnection_AutoDetectSourceLanguages\";\n  /**\n   * The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have\n   * to use this property directly.\n   * Instead use [[SpeechConfig.outputFormat]].\n   * @member PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestDetailedResultTrueFalse\"] = 21] = \"SpeechServiceResponse_RequestDetailedResultTrueFalse\";\n  /**\n   * The requested Cognitive Services Speech Service response output profanity level. Currently unused.\n   * @member PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestProfanityFilterTrueFalse\"] = 22] = \"SpeechServiceResponse_RequestProfanityFilterTrueFalse\";\n  /**\n   * The Cognitive Services Speech Service response output (in JSON format). This property is available on recognition result objects only.\n   * @member PropertyId.SpeechServiceResponse_JsonResult\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_JsonResult\"] = 23] = \"SpeechServiceResponse_JsonResult\";\n  /**\n   * The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to\n   * use this property directly. Instead use [[CancellationDetails.errorDetails]].\n   * @member PropertyId.SpeechServiceResponse_JsonErrorDetails\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_JsonErrorDetails\"] = 24] = \"SpeechServiceResponse_JsonErrorDetails\";\n  /**\n   * The cancellation reason. Currently unused.\n   * @member PropertyId.CancellationDetails_Reason\n   */\n  PropertyId[PropertyId[\"CancellationDetails_Reason\"] = 25] = \"CancellationDetails_Reason\";\n  /**\n   * The cancellation text. Currently unused.\n   * @member PropertyId.CancellationDetails_ReasonText\n   */\n  PropertyId[PropertyId[\"CancellationDetails_ReasonText\"] = 26] = \"CancellationDetails_ReasonText\";\n  /**\n   * The Cancellation detailed text. Currently unused.\n   * @member PropertyId.CancellationDetails_ReasonDetailedText\n   */\n  PropertyId[PropertyId[\"CancellationDetails_ReasonDetailedText\"] = 27] = \"CancellationDetails_ReasonDetailedText\";\n  /**\n   * The Language Understanding Service response output (in JSON format). Available via [[IntentRecognitionResult]]\n   * @member PropertyId.LanguageUnderstandingServiceResponse_JsonResult\n   */\n  PropertyId[PropertyId[\"LanguageUnderstandingServiceResponse_JsonResult\"] = 28] = \"LanguageUnderstandingServiceResponse_JsonResult\";\n  /**\n   * The URL string built from speech configuration.\n   * This property is intended to be read-only. The SDK is using it internally.\n   * NOTE: Added in version 1.7.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_Url\"] = 29] = \"SpeechServiceConnection_Url\";\n  /**\n   * The initial silence timeout value (in milliseconds) used by the service.\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_InitialSilenceTimeoutMs\"] = 30] = \"SpeechServiceConnection_InitialSilenceTimeoutMs\";\n  /**\n   * The end silence timeout value (in milliseconds) used by the service.\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_EndSilenceTimeoutMs\"] = 31] = \"SpeechServiceConnection_EndSilenceTimeoutMs\";\n  /**\n   * A duration of detected silence, measured in milliseconds, after which speech-to-text will determine a spoken\n   * phrase has ended and generate a final Recognized result. Configuring this timeout may be helpful in situations\n   * where spoken input is significantly faster or slower than usual and default segmentation behavior consistently\n   * yields results that are too long or too short. Segmentation timeout values that are inappropriately high or low\n   * can negatively affect speech-to-text accuracy; this property should be carefully configured and the resulting\n   * behavior should be thoroughly validated as intended.\n   *\n   * For more information about timeout configuration that includes discussion of default behaviors, please visit\n   * https://aka.ms/csspeech/timeouts.\n   *\n   * Added in version 1.21.0.\n   */\n  PropertyId[PropertyId[\"Speech_SegmentationSilenceTimeoutMs\"] = 32] = \"Speech_SegmentationSilenceTimeoutMs\";\n  /**\n   * A boolean value specifying whether audio logging is enabled in the service or not.\n   * Audio and content logs are stored either in Microsoft-owned storage, or in your own storage account linked\n   * to your Cognitive Services subscription (Bring Your Own Storage (BYOS) enabled Speech resource).\n   * The logs will be removed after 30 days.\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_EnableAudioLogging\"] = 33] = \"SpeechServiceConnection_EnableAudioLogging\";\n  /**\n   * The speech service connection language identifier mode.\n   * Can be \"AtStart\" (the default), or \"Continuous\". See Language\n   * Identification document https://aka.ms/speech/lid?pivots=programming-language-javascript\n   * for more details.\n   * Added in 1.25.0\n   **/\n  PropertyId[PropertyId[\"SpeechServiceConnection_LanguageIdMode\"] = 34] = \"SpeechServiceConnection_LanguageIdMode\";\n  /**\n   * A string value representing the desired endpoint version to target for Speech Recognition.\n   * Added in version 1.21.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_RecognitionEndpointVersion\"] = 35] = \"SpeechServiceConnection_RecognitionEndpointVersion\";\n  /**\n  /**\n   * A string value the current speaker recognition scenario/mode (TextIndependentIdentification, etc.).\n   * Added in version 1.23.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_SpeakerIdMode\"] = 36] = \"SpeechServiceConnection_SpeakerIdMode\";\n  /**\n   * The requested Cognitive Services Speech Service response output profanity setting.\n   * Allowed values are \"masked\", \"removed\", and \"raw\".\n   * Added in version 1.7.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_ProfanityOption\"] = 37] = \"SpeechServiceResponse_ProfanityOption\";\n  /**\n   * A string value specifying which post processing option should be used by service.\n   * Allowed values are \"TrueText\".\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_PostProcessingOption\"] = 38] = \"SpeechServiceResponse_PostProcessingOption\";\n  /**\n   * A boolean value specifying whether to include word-level timestamps in the response result.\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestWordLevelTimestamps\"] = 39] = \"SpeechServiceResponse_RequestWordLevelTimestamps\";\n  /**\n   * The number of times a word has to be in partial results to be returned.\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_StablePartialResultThreshold\"] = 40] = \"SpeechServiceResponse_StablePartialResultThreshold\";\n  /**\n   * A string value specifying the output format option in the response result. Internal use only.\n   * Added in version 1.7.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_OutputFormatOption\"] = 41] = \"SpeechServiceResponse_OutputFormatOption\";\n  /**\n   * A boolean value to request for stabilizing translation partial results by omitting words in the end.\n   * Added in version 1.7.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_TranslationRequestStablePartialResult\"] = 42] = \"SpeechServiceResponse_TranslationRequestStablePartialResult\";\n  /**\n   * A boolean value specifying whether to request WordBoundary events.\n   * @member PropertyId.SpeechServiceResponse_RequestWordBoundary\n   * Added in version 1.21.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestWordBoundary\"] = 43] = \"SpeechServiceResponse_RequestWordBoundary\";\n  /**\n   * A boolean value specifying whether to request punctuation boundary in WordBoundary Events. Default is true.\n   * @member PropertyId.SpeechServiceResponse_RequestPunctuationBoundary\n   * Added in version 1.21.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestPunctuationBoundary\"] = 44] = \"SpeechServiceResponse_RequestPunctuationBoundary\";\n  /**\n   * A boolean value specifying whether to request sentence boundary in WordBoundary Events. Default is false.\n   * @member PropertyId.SpeechServiceResponse_RequestSentenceBoundary\n   * Added in version 1.21.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestSentenceBoundary\"] = 45] = \"SpeechServiceResponse_RequestSentenceBoundary\";\n  /**\n   * Identifier used to connect to the backend service.\n   * @member PropertyId.Conversation_ApplicationId\n   */\n  PropertyId[PropertyId[\"Conversation_ApplicationId\"] = 46] = \"Conversation_ApplicationId\";\n  /**\n   * Type of dialog backend to connect to.\n   * @member PropertyId.Conversation_DialogType\n   */\n  PropertyId[PropertyId[\"Conversation_DialogType\"] = 47] = \"Conversation_DialogType\";\n  /**\n   * Silence timeout for listening\n   * @member PropertyId.Conversation_Initial_Silence_Timeout\n   */\n  PropertyId[PropertyId[\"Conversation_Initial_Silence_Timeout\"] = 48] = \"Conversation_Initial_Silence_Timeout\";\n  /**\n   * From Id to add to speech recognition activities.\n   * @member PropertyId.Conversation_From_Id\n   */\n  PropertyId[PropertyId[\"Conversation_From_Id\"] = 49] = \"Conversation_From_Id\";\n  /**\n   * ConversationId for the session.\n   * @member PropertyId.Conversation_Conversation_Id\n   */\n  PropertyId[PropertyId[\"Conversation_Conversation_Id\"] = 50] = \"Conversation_Conversation_Id\";\n  /**\n   * Comma separated list of custom voice deployment ids.\n   * @member PropertyId.Conversation_Custom_Voice_Deployment_Ids\n   */\n  PropertyId[PropertyId[\"Conversation_Custom_Voice_Deployment_Ids\"] = 51] = \"Conversation_Custom_Voice_Deployment_Ids\";\n  /**\n   * Speech activity template, stamp properties from the template on the activity generated by the service for speech.\n   * @member PropertyId.Conversation_Speech_Activity_Template\n   * Added in version 1.10.0.\n   */\n  PropertyId[PropertyId[\"Conversation_Speech_Activity_Template\"] = 52] = \"Conversation_Speech_Activity_Template\";\n  /**\n   * Enables or disables the receipt of turn status messages as obtained on the turnStatusReceived event.\n   * @member PropertyId.Conversation_Request_Bot_Status_Messages\n   * Added in version 1.15.0.\n   */\n  PropertyId[PropertyId[\"Conversation_Request_Bot_Status_Messages\"] = 53] = \"Conversation_Request_Bot_Status_Messages\";\n  /**\n   * Specifies the connection ID to be provided in the Agent configuration message, e.g. a Direct Line token for\n   * channel authentication.\n   * Added in version 1.15.1.\n   */\n  PropertyId[PropertyId[\"Conversation_Agent_Connection_Id\"] = 54] = \"Conversation_Agent_Connection_Id\";\n  /**\n   * The Cognitive Services Speech Service host (url). Under normal circumstances, you shouldn't have to use this property directly.\n   * Instead, use [[SpeechConfig.fromHost]].\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_Host\"] = 55] = \"SpeechServiceConnection_Host\";\n  /**\n   * Set the host for service calls to the Conversation Translator REST management and websocket calls.\n   */\n  PropertyId[PropertyId[\"ConversationTranslator_Host\"] = 56] = \"ConversationTranslator_Host\";\n  /**\n   * Optionally set the the host's display name.\n   * Used when joining a conversation.\n   */\n  PropertyId[PropertyId[\"ConversationTranslator_Name\"] = 57] = \"ConversationTranslator_Name\";\n  /**\n   * Optionally set a value for the X-CorrelationId request header.\n   * Used for troubleshooting errors in the server logs. It should be a valid guid.\n   */\n  PropertyId[PropertyId[\"ConversationTranslator_CorrelationId\"] = 58] = \"ConversationTranslator_CorrelationId\";\n  /**\n   * Set the conversation token to be sent to the speech service. This enables the\n   * service to service call from the speech service to the Conversation Translator service for relaying\n   * recognitions. For internal use.\n   */\n  PropertyId[PropertyId[\"ConversationTranslator_Token\"] = 59] = \"ConversationTranslator_Token\";\n  /**\n   * The reference text of the audio for pronunciation evaluation.\n   * For this and the following pronunciation assessment parameters, see\n   * https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters for details.\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_ReferenceText\"] = 60] = \"PronunciationAssessment_ReferenceText\";\n  /**\n   * The point system for pronunciation score calibration (FivePoint or HundredMark).\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_GradingSystem\"] = 61] = \"PronunciationAssessment_GradingSystem\";\n  /**\n   * The pronunciation evaluation granularity (Phoneme, Word, or FullText).\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_Granularity\"] = 62] = \"PronunciationAssessment_Granularity\";\n  /**\n   * Defines if enable miscue calculation.\n   * With this enabled, the pronounced words will be compared to the reference text,\n   * and will be marked with omission/insertion based on the comparison. The default setting is False.\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_EnableMiscue\"] = 63] = \"PronunciationAssessment_EnableMiscue\";\n  /**\n   * The json string of pronunciation assessment parameters\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_Json\"] = 64] = \"PronunciationAssessment_Json\";\n  /**\n   * Pronunciation assessment parameters.\n   * This property is intended to be read-only. The SDK is using it internally.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_Params\"] = 65] = \"PronunciationAssessment_Params\";\n  /**\n   * Version of Speaker Recognition API to use.\n   * Added in version 1.18.0\n   */\n  PropertyId[PropertyId[\"SpeakerRecognition_Api_Version\"] = 66] = \"SpeakerRecognition_Api_Version\";\n  /**\n   * Specifies whether to allow load of data URL for web worker\n   * Allowed values are \"off\" and \"on\". Default is \"on\".\n   * Added in version 1.32.0\n   */\n  PropertyId[PropertyId[\"WebWorkerLoadType\"] = 67] = \"WebWorkerLoadType\";\n  /**\n   * Talking avatar service WebRTC session description protocol.\n   * This property is intended to be read-only. The SDK is using it internally.\n   * Added in version 1.33.0\n   */\n  PropertyId[PropertyId[\"TalkingAvatarService_WebRTC_SDP\"] = 68] = \"TalkingAvatarService_WebRTC_SDP\";\n})(PropertyId = exports.PropertyId || (exports.PropertyId = {}));\n\n//# sourceMappingURL=PropertyId.js.map","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}