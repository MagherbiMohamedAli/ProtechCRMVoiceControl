{"ast":null,"code":"\"use strict\";\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.DialogServiceAdapter = void 0;\nconst Exports_js_1 = require(\"../common.browser/Exports.js\");\nconst DialogEvents_js_1 = require(\"../common/DialogEvents.js\");\nconst Exports_js_2 = require(\"../common/Exports.js\");\nconst AudioOutputFormat_js_1 = require(\"../sdk/Audio/AudioOutputFormat.js\");\nconst Exports_js_3 = require(\"../sdk/Exports.js\");\nconst DialogServiceTurnStateManager_js_1 = require(\"./DialogServiceTurnStateManager.js\");\nconst Exports_js_4 = require(\"./Exports.js\");\nconst ActivityResponsePayload_js_1 = require(\"./ServiceMessages/ActivityResponsePayload.js\");\nconst SpeechConnectionMessage_Internal_js_1 = require(\"./SpeechConnectionMessage.Internal.js\");\nclass DialogServiceAdapter extends Exports_js_4.ServiceRecognizerBase {\n  constructor(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector) {\n    super(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector);\n    this.privEvents = new Exports_js_2.EventSource();\n    this.privDialogServiceConnector = dialogServiceConnector;\n    this.receiveMessageOverride = () => this.receiveDialogMessageOverride();\n    this.privTurnStateManager = new DialogServiceTurnStateManager_js_1.DialogServiceTurnStateManager();\n    this.recognizeOverride = (recoMode, successCallback, errorCallback) => this.listenOnce(recoMode, successCallback, errorCallback);\n    this.postConnectImplOverride = connection => this.dialogConnectImpl(connection);\n    this.configConnectionOverride = connection => this.configConnection(connection);\n    this.disconnectOverride = () => this.privDisconnect();\n    this.privDialogAudioSource = audioSource;\n    this.agentConfigSent = false;\n    this.privLastResult = null;\n    this.connectionEvents.attach(connectionEvent => {\n      if (connectionEvent.name === \"ConnectionClosedEvent\") {\n        this.terminateMessageLoop = true;\n      }\n    });\n  }\n  sendMessage(message) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const interactionGuid = Exports_js_2.createGuid();\n      const requestId = Exports_js_2.createNoDashGuid();\n      const agentMessage = {\n        context: {\n          interactionId: interactionGuid\n        },\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n        messagePayload: JSON.parse(message),\n        version: 0.5\n      };\n      const agentMessageJson = JSON.stringify(agentMessage);\n      const connection = yield this.fetchConnection();\n      yield connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, \"agent\", requestId, \"application/json\", agentMessageJson));\n    });\n  }\n  privDisconnect() {\n    return __awaiter(this, void 0, void 0, function* () {\n      yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.NoError, \"Disconnecting\");\n      this.terminateMessageLoop = true;\n      this.agentConfigSent = false;\n      return;\n    });\n  }\n  processTypeSpecificMessages(connectionMessage) {\n    const resultProps = new Exports_js_3.PropertyCollection();\n    if (connectionMessage.messageType === Exports_js_2.MessageType.Text) {\n      resultProps.setProperty(Exports_js_3.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n    }\n    let result;\n    let processed;\n    switch (connectionMessage.path.toLowerCase()) {\n      case \"speech.phrase\":\n        const speechPhrase = Exports_js_4.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody);\n        this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + speechPhrase.Offset + speechPhrase.Duration);\n        if (speechPhrase.RecognitionStatus !== Exports_js_4.RecognitionStatus.TooManyRequests && speechPhrase.RecognitionStatus !== Exports_js_4.RecognitionStatus.Error) {\n          const args = this.fireEventForResult(speechPhrase, resultProps);\n          this.privLastResult = args.result;\n          if (!!this.privDialogServiceConnector.recognized) {\n            try {\n              this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, args);\n              /* eslint-disable no-empty */\n            } catch (error) {\n              // Not going to let errors in the event handler\n              // trip things up.\n            }\n          }\n        }\n        processed = true;\n        break;\n      case \"speech.hypothesis\":\n        const hypothesis = Exports_js_4.SpeechHypothesis.fromJSON(connectionMessage.textBody);\n        const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;\n        result = new Exports_js_3.SpeechRecognitionResult(this.privRequestSession.requestId, Exports_js_3.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, undefined, undefined, connectionMessage.textBody, resultProps);\n        this.privRequestSession.onHypothesis(offset);\n        const ev = new Exports_js_3.SpeechRecognitionEventArgs(result, hypothesis.Duration, this.privRequestSession.sessionId);\n        if (!!this.privDialogServiceConnector.recognizing) {\n          try {\n            this.privDialogServiceConnector.recognizing(this.privDialogServiceConnector, ev);\n            /* eslint-disable no-empty */\n          } catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n          }\n        }\n        processed = true;\n        break;\n      case \"speech.keyword\":\n        const keyword = Exports_js_4.SpeechKeyword.fromJSON(connectionMessage.textBody);\n        result = new Exports_js_3.SpeechRecognitionResult(this.privRequestSession.requestId, keyword.Status === \"Accepted\" ? Exports_js_3.ResultReason.RecognizedKeyword : Exports_js_3.ResultReason.NoMatch, keyword.Text, keyword.Duration, keyword.Offset, undefined, undefined, undefined, undefined, connectionMessage.textBody, resultProps);\n        if (keyword.Status !== \"Accepted\") {\n          this.privLastResult = result;\n        }\n        const event = new Exports_js_3.SpeechRecognitionEventArgs(result, result.duration, result.resultId);\n        if (!!this.privDialogServiceConnector.recognized) {\n          try {\n            this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, event);\n            /* eslint-disable no-empty */\n          } catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n          }\n        }\n        processed = true;\n        break;\n      case \"audio\":\n        {\n          const audioRequestId = connectionMessage.requestId.toUpperCase();\n          const turn = this.privTurnStateManager.GetTurn(audioRequestId);\n          try {\n            // Empty binary message signals end of stream.\n            if (!connectionMessage.binaryBody) {\n              turn.endAudioStream();\n            } else {\n              turn.audioStream.write(connectionMessage.binaryBody);\n            }\n          } catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n          }\n        }\n        processed = true;\n        break;\n      case \"response\":\n        {\n          this.handleResponseMessage(connectionMessage);\n        }\n        processed = true;\n        break;\n      default:\n        break;\n    }\n    const defferal = new Exports_js_2.Deferred();\n    defferal.resolve(processed);\n    return defferal.promise;\n  }\n  // Cancels recognition.\n  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.terminateMessageLoop = true;\n      if (!!this.privRequestSession.isRecognizing) {\n        yield this.privRequestSession.onStopRecognizing();\n      }\n      if (!!this.privDialogServiceConnector.canceled) {\n        const properties = new Exports_js_3.PropertyCollection();\n        properties.setProperty(Exports_js_4.CancellationErrorCodePropertyName, Exports_js_3.CancellationErrorCode[errorCode]);\n        const cancelEvent = new Exports_js_3.SpeechRecognitionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);\n        try {\n          this.privDialogServiceConnector.canceled(this.privDialogServiceConnector, cancelEvent);\n          /* eslint-disable no-empty */\n        } catch (_a) {}\n        if (!!this.privSuccessCallback) {\n          const result = new Exports_js_3.SpeechRecognitionResult(undefined,\n          // ResultId\n          Exports_js_3.ResultReason.Canceled, undefined,\n          // Text\n          undefined,\n          // Duration\n          undefined,\n          // Offset\n          undefined,\n          // Language\n          undefined,\n          // Language Detection Confidence\n          undefined,\n          // Speaker Id\n          error, undefined,\n          // Json\n          properties);\n          try {\n            this.privSuccessCallback(result);\n            this.privSuccessCallback = undefined;\n            /* eslint-disable no-empty */\n          } catch (_b) {}\n        }\n      }\n    });\n  }\n  listenOnce(recoMode, successCallback, errorCallback) {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.privRecognizerConfig.recognitionMode = recoMode;\n      this.privSuccessCallback = successCallback;\n      this.privErrorCallback = errorCallback;\n      this.privRequestSession.startNewRecognition();\n      this.privRequestSession.listenForServiceTelemetry(this.privDialogAudioSource.events);\n      this.privRecognizerConfig.parameters.setProperty(Exports_js_3.PropertyId.Speech_SessionId, this.privRequestSession.sessionId);\n      // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().\n      const conPromise = this.connectImpl();\n      const preAudioPromise = this.sendPreAudioMessages();\n      const node = yield this.privDialogAudioSource.attach(this.privRequestSession.audioNodeId);\n      const format = yield this.privDialogAudioSource.format;\n      const deviceInfo = yield this.privDialogAudioSource.deviceInfo;\n      const audioNode = new Exports_js_1.ReplayableAudioNode(node, format.avgBytesPerSec);\n      yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);\n      this.privRecognizerConfig.SpeechServiceConfig.Context.audio = {\n        source: deviceInfo\n      };\n      try {\n        yield conPromise;\n        yield preAudioPromise;\n      } catch (error) {\n        yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.ConnectionFailure, error);\n        return Promise.resolve();\n      }\n      const sessionStartEventArgs = new Exports_js_3.SessionEventArgs(this.privRequestSession.sessionId);\n      if (!!this.privRecognizer.sessionStarted) {\n        this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);\n      }\n      const audioSendPromise = this.sendAudio(audioNode);\n      // /* eslint-disable no-empty */\n      audioSendPromise.then(() => {}, error => __awaiter(this, void 0, void 0, function* () {\n        yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.RuntimeError, error);\n      }));\n    });\n  }\n  // Establishes a websocket connection to the end point.\n  dialogConnectImpl(connection) {\n    this.privConnectionLoop = this.startMessageLoop();\n    return connection;\n  }\n  receiveDialogMessageOverride() {\n    // we won't rely on the cascading promises of the connection since we want to continually be available to receive messages\n    const communicationCustodian = new Exports_js_2.Deferred();\n    const loop = () => __awaiter(this, void 0, void 0, function* () {\n      try {\n        const isDisposed = this.isDisposed();\n        const terminateMessageLoop = !this.isDisposed() && this.terminateMessageLoop;\n        if (isDisposed || terminateMessageLoop) {\n          // We're done.\n          communicationCustodian.resolve(undefined);\n          return;\n        }\n        const connection = yield this.fetchConnection();\n        const message = yield connection.read();\n        if (!message) {\n          return loop();\n        }\n        const connectionMessage = SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage.fromConnectionMessage(message);\n        switch (connectionMessage.path.toLowerCase()) {\n          case \"turn.start\":\n            {\n              const turnRequestId = connectionMessage.requestId.toUpperCase();\n              const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();\n              // turn started by the service\n              if (turnRequestId !== audioSessionReqId) {\n                this.privTurnStateManager.StartTurn(turnRequestId);\n              } else {\n                this.privRequestSession.onServiceTurnStartResponse();\n              }\n            }\n            break;\n          case \"speech.startdetected\":\n            const speechStartDetected = Exports_js_4.SpeechDetected.fromJSON(connectionMessage.textBody);\n            const speechStartEventArgs = new Exports_js_3.RecognitionEventArgs(speechStartDetected.Offset, this.privRequestSession.sessionId);\n            if (!!this.privRecognizer.speechStartDetected) {\n              this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);\n            }\n            break;\n          case \"speech.enddetected\":\n            let json;\n            if (connectionMessage.textBody.length > 0) {\n              json = connectionMessage.textBody;\n            } else {\n              // If the request was empty, the JSON returned is empty.\n              json = \"{ Offset: 0 }\";\n            }\n            const speechStopDetected = Exports_js_4.SpeechDetected.fromJSON(json);\n            this.privRequestSession.onServiceRecognized(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset);\n            const speechStopEventArgs = new Exports_js_3.RecognitionEventArgs(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);\n            if (!!this.privRecognizer.speechEndDetected) {\n              this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);\n            }\n            break;\n          case \"turn.end\":\n            {\n              const turnEndRequestId = connectionMessage.requestId.toUpperCase();\n              const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();\n              // turn started by the service\n              if (turnEndRequestId !== audioSessionReqId) {\n                this.privTurnStateManager.CompleteTurn(turnEndRequestId);\n              } else {\n                // Audio session turn\n                const sessionStopEventArgs = new Exports_js_3.SessionEventArgs(this.privRequestSession.sessionId);\n                yield this.privRequestSession.onServiceTurnEndResponse(false);\n                if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {\n                  if (!!this.privRecognizer.sessionStopped) {\n                    this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);\n                  }\n                }\n                // report result to promise.\n                if (!!this.privSuccessCallback && this.privLastResult) {\n                  try {\n                    this.privSuccessCallback(this.privLastResult);\n                    this.privLastResult = null;\n                  } catch (e) {\n                    if (!!this.privErrorCallback) {\n                      this.privErrorCallback(e);\n                    }\n                  }\n                  // Only invoke the call back once.\n                  // and if it's successful don't invoke the\n                  // error after that.\n                  this.privSuccessCallback = undefined;\n                  this.privErrorCallback = undefined;\n                }\n              }\n            }\n            break;\n          default:\n            try {\n              const processed = yield this.processTypeSpecificMessages(connectionMessage);\n              if (!processed) {\n                if (!!this.serviceEvents) {\n                  this.serviceEvents.onEvent(new Exports_js_2.ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));\n                }\n              }\n            } catch (e) {\n              //\n            }\n        }\n        const ret = loop();\n        return ret;\n      } catch (error) {\n        this.terminateMessageLoop = true;\n        communicationCustodian.resolve();\n      }\n    });\n    loop().catch(reason => {\n      Exports_js_2.Events.instance.onEvent(new Exports_js_2.BackgroundEvent(reason));\n    });\n    return communicationCustodian.promise;\n  }\n  startMessageLoop() {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.terminateMessageLoop = false;\n      try {\n        yield this.receiveDialogMessageOverride();\n      } catch (error) {\n        yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.RuntimeError, error);\n      }\n      return Promise.resolve();\n    });\n  }\n  // Takes an established websocket connection to the endpoint and sends speech configuration information.\n  configConnection(connection) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.terminateMessageLoop) {\n        this.terminateMessageLoop = false;\n        return Promise.reject(\"Connection to service terminated.\");\n      }\n      yield this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());\n      yield this.sendAgentConfig(connection);\n      return connection;\n    });\n  }\n  sendPreAudioMessages() {\n    return __awaiter(this, void 0, void 0, function* () {\n      const connection = yield this.fetchConnection();\n      this.addKeywordContextData();\n      yield this.sendSpeechContext(connection, true);\n      yield this.sendAgentContext(connection);\n      yield this.sendWaveHeader(connection);\n    });\n  }\n  sendAgentConfig(connection) {\n    if (this.agentConfig && !this.agentConfigSent) {\n      if (this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.Conversation_DialogType) === Exports_js_3.DialogServiceConfig.DialogTypes.CustomCommands) {\n        const config = this.agentConfig.get();\n        config.botInfo.commandsCulture = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage, \"en-us\");\n        this.agentConfig.set(config);\n      }\n      this.onEvent(new DialogEvents_js_1.SendingAgentContextMessageEvent(this.agentConfig));\n      const agentConfigJson = this.agentConfig.toJsonString();\n      // guard against sending this multiple times on one connection\n      this.agentConfigSent = true;\n      return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, \"agent.config\", this.privRequestSession.requestId, \"application/json\", agentConfigJson));\n    }\n    return;\n  }\n  sendAgentContext(connection) {\n    const guid = Exports_js_2.createGuid();\n    const speechActivityTemplate = this.privDialogServiceConnector.properties.getProperty(Exports_js_3.PropertyId.Conversation_Speech_Activity_Template);\n    const agentContext = {\n      channelData: \"\",\n      context: {\n        interactionId: guid\n      },\n      messagePayload: typeof speechActivityTemplate === undefined ? undefined : speechActivityTemplate,\n      version: 0.5\n    };\n    const agentContextJson = JSON.stringify(agentContext);\n    return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, \"speech.agent.context\", this.privRequestSession.requestId, \"application/json\", agentContextJson));\n  }\n  fireEventForResult(serviceResult, properties) {\n    const resultReason = Exports_js_4.EnumTranslation.implTranslateRecognitionResult(serviceResult.RecognitionStatus);\n    const offset = serviceResult.Offset + this.privRequestSession.currentTurnAudioOffset;\n    const result = new Exports_js_3.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, serviceResult.DisplayText, serviceResult.Duration, offset, serviceResult.Language, serviceResult.LanguageDetectionConfidence, undefined, undefined, JSON.stringify(serviceResult), properties);\n    const ev = new Exports_js_3.SpeechRecognitionEventArgs(result, offset, this.privRequestSession.sessionId);\n    return ev;\n  }\n  handleResponseMessage(responseMessage) {\n    // \"response\" messages can contain either \"message\" (activity) or \"MessageStatus\" data. Fire the appropriate\n    // event according to the message type that's specified.\n    const responsePayload = JSON.parse(responseMessage.textBody);\n    switch (responsePayload.messageType.toLowerCase()) {\n      case \"message\":\n        const responseRequestId = responseMessage.requestId.toUpperCase();\n        const activityPayload = ActivityResponsePayload_js_1.ActivityPayloadResponse.fromJSON(responseMessage.textBody);\n        const turn = this.privTurnStateManager.GetTurn(responseRequestId);\n        // update the conversation Id\n        if (activityPayload.conversationId) {\n          const updateAgentConfig = this.agentConfig.get();\n          updateAgentConfig.botInfo.conversationId = activityPayload.conversationId;\n          this.agentConfig.set(updateAgentConfig);\n        }\n        const pullAudioOutputStream = turn.processActivityPayload(activityPayload, AudioOutputFormat_js_1.AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(this.privDialogServiceConnector.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)));\n        const activity = new Exports_js_3.ActivityReceivedEventArgs(activityPayload.messagePayload, pullAudioOutputStream);\n        if (!!this.privDialogServiceConnector.activityReceived) {\n          try {\n            this.privDialogServiceConnector.activityReceived(this.privDialogServiceConnector, activity);\n            /* eslint-disable-next-line no-empty */\n          } catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n          }\n        }\n        break;\n      case \"messagestatus\":\n        if (!!this.privDialogServiceConnector.turnStatusReceived) {\n          try {\n            this.privDialogServiceConnector.turnStatusReceived(this.privDialogServiceConnector, new Exports_js_3.TurnStatusReceivedEventArgs(responseMessage.textBody));\n            /* eslint-disable-next-line no-empty */\n          } catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n          }\n        }\n        break;\n      default:\n        Exports_js_2.Events.instance.onEvent(new Exports_js_2.BackgroundEvent(`Unexpected response of type ${responsePayload.messageType}. Ignoring.`));\n        break;\n    }\n  }\n  onEvent(event) {\n    this.privEvents.onEvent(event);\n    Exports_js_2.Events.instance.onEvent(event);\n  }\n  addKeywordContextData() {\n    const keywordPropertyValue = this.privRecognizerConfig.parameters.getProperty(\"SPEECH-KeywordsToDetect\");\n    if (keywordPropertyValue === undefined) {\n      return;\n    }\n    const keywordOffsetPropertyValue = this.privRecognizerConfig.parameters.getProperty(\"SPEECH-KeywordsToDetect-Offsets\");\n    const keywordDurationPropertyValue = this.privRecognizerConfig.parameters.getProperty(\"SPEECH-KeywordsToDetect-Durations\");\n    const keywords = keywordPropertyValue.split(\";\");\n    const keywordOffsets = keywordOffsetPropertyValue === undefined ? [] : keywordOffsetPropertyValue.split(\";\");\n    const keywordDurations = keywordDurationPropertyValue === undefined ? [] : keywordDurationPropertyValue.split(\";\");\n    const keywordDefinitionArray = [];\n    for (let i = 0; i < keywords.length; i++) {\n      const definition = {};\n      definition.text = keywords[i];\n      if (i < keywordOffsets.length) {\n        definition.offset = Number(keywordOffsets[i]);\n      }\n      if (i < keywordDurations.length) {\n        definition.duration = Number(keywordDurations[i]);\n      }\n      keywordDefinitionArray.push(definition);\n    }\n    this.speechContext.setSection(\"invocationSource\", \"VoiceActivationWithKeyword\");\n    this.speechContext.setSection(\"keywordDetection\", [{\n      clientDetectedKeywords: keywordDefinitionArray,\n      onReject: {\n        action: \"EndOfTurn\"\n      },\n      type: \"startTrigger\"\n    }]);\n  }\n}\nexports.DialogServiceAdapter = DialogServiceAdapter;\n\n//# sourceMappingURL=DialogServiceAdapter.js.map","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}