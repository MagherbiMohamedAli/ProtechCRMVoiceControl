{"ast":null,"code":"\"use strict\";\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.MicAudioSource = exports.AudioWorkletSourceURLPropertyName = void 0;\nconst Exports_js_1 = require(\"../common.speech/Exports.js\");\nconst Exports_js_2 = require(\"../common/Exports.js\");\nconst AudioStreamFormat_js_1 = require(\"../sdk/Audio/AudioStreamFormat.js\");\nexports.AudioWorkletSourceURLPropertyName = \"MICROPHONE-WorkletSourceUrl\";\nclass MicAudioSource {\n  constructor(privRecorder, deviceId, audioSourceId, mediaStream) {\n    this.privRecorder = privRecorder;\n    this.deviceId = deviceId;\n    this.privStreams = {};\n    this.privOutputChunkSize = MicAudioSource.AUDIOFORMAT.avgBytesPerSec / 10;\n    this.privId = audioSourceId ? audioSourceId : Exports_js_2.createNoDashGuid();\n    this.privEvents = new Exports_js_2.EventSource();\n    this.privMediaStream = mediaStream || null;\n    this.privIsClosing = false;\n  }\n  get format() {\n    return Promise.resolve(MicAudioSource.AUDIOFORMAT);\n  }\n  turnOn() {\n    if (this.privInitializeDeferral) {\n      return this.privInitializeDeferral.promise;\n    }\n    this.privInitializeDeferral = new Exports_js_2.Deferred();\n    try {\n      this.createAudioContext();\n    } catch (error) {\n      if (error instanceof Error) {\n        const typedError = error;\n        this.privInitializeDeferral.reject(typedError.name + \": \" + typedError.message);\n      } else {\n        this.privInitializeDeferral.reject(error);\n      }\n      return this.privInitializeDeferral.promise;\n    }\n    const nav = window.navigator;\n    let getUserMedia =\n    // eslint-disable-next-line\n    nav.getUserMedia || nav.webkitGetUserMedia || nav.mozGetUserMedia || nav.msGetUserMedia;\n    if (!!nav.mediaDevices) {\n      getUserMedia = (constraints, successCallback, errorCallback) => {\n        nav.mediaDevices.getUserMedia(constraints).then(successCallback).catch(errorCallback);\n      };\n    }\n    if (!getUserMedia) {\n      const errorMsg = \"Browser does not support getUserMedia.\";\n      this.privInitializeDeferral.reject(errorMsg);\n      this.onEvent(new Exports_js_2.AudioSourceErrorEvent(errorMsg, \"\")); // mic initialized error - no streamid at this point\n    } else {\n      const next = () => {\n        this.onEvent(new Exports_js_2.AudioSourceInitializingEvent(this.privId)); // no stream id\n        if (this.privMediaStream && this.privMediaStream.active) {\n          this.onEvent(new Exports_js_2.AudioSourceReadyEvent(this.privId));\n          this.privInitializeDeferral.resolve();\n        } else {\n          getUserMedia({\n            audio: this.deviceId ? {\n              deviceId: this.deviceId\n            } : true,\n            video: false\n          }, mediaStream => {\n            this.privMediaStream = mediaStream;\n            this.onEvent(new Exports_js_2.AudioSourceReadyEvent(this.privId));\n            this.privInitializeDeferral.resolve();\n          }, error => {\n            const errorMsg = `Error occurred during microphone initialization: ${error}`;\n            this.privInitializeDeferral.reject(errorMsg);\n            this.onEvent(new Exports_js_2.AudioSourceErrorEvent(this.privId, errorMsg));\n          });\n        }\n      };\n      if (this.privContext.state === \"suspended\") {\n        // NOTE: On iOS, the Web Audio API requires sounds to be triggered from an explicit user action.\n        // https://github.com/WebAudio/web-audio-api/issues/790\n        this.privContext.resume().then(next).catch(reason => {\n          this.privInitializeDeferral.reject(`Failed to initialize audio context: ${reason}`);\n        });\n      } else {\n        next();\n      }\n    }\n    return this.privInitializeDeferral.promise;\n  }\n  id() {\n    return this.privId;\n  }\n  attach(audioNodeId) {\n    this.onEvent(new Exports_js_2.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));\n    return this.listen(audioNodeId).then(stream => {\n      this.onEvent(new Exports_js_2.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));\n      return {\n        detach: () => __awaiter(this, void 0, void 0, function* () {\n          stream.readEnded();\n          delete this.privStreams[audioNodeId];\n          this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n          return this.turnOff();\n        }),\n        id: () => audioNodeId,\n        read: () => stream.read()\n      };\n    });\n  }\n  detach(audioNodeId) {\n    if (audioNodeId && this.privStreams[audioNodeId]) {\n      this.privStreams[audioNodeId].close();\n      delete this.privStreams[audioNodeId];\n      this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n    }\n  }\n  turnOff() {\n    return __awaiter(this, void 0, void 0, function* () {\n      for (const streamId in this.privStreams) {\n        if (streamId) {\n          const stream = this.privStreams[streamId];\n          if (stream) {\n            stream.close();\n          }\n        }\n      }\n      this.onEvent(new Exports_js_2.AudioSourceOffEvent(this.privId)); // no stream now\n      if (this.privInitializeDeferral) {\n        // Correctly handle when browser forces mic off before turnOn() completes\n        // eslint-disable-next-line @typescript-eslint/await-thenable\n        yield this.privInitializeDeferral;\n        this.privInitializeDeferral = null;\n      }\n      yield this.destroyAudioContext();\n      return;\n    });\n  }\n  get events() {\n    return this.privEvents;\n  }\n  get deviceInfo() {\n    return this.getMicrophoneLabel().then(label => ({\n      bitspersample: MicAudioSource.AUDIOFORMAT.bitsPerSample,\n      channelcount: MicAudioSource.AUDIOFORMAT.channels,\n      connectivity: Exports_js_1.connectivity.Unknown,\n      manufacturer: \"Speech SDK\",\n      model: label,\n      samplerate: MicAudioSource.AUDIOFORMAT.samplesPerSec,\n      type: Exports_js_1.type.Microphones\n    }));\n  }\n  setProperty(name, value) {\n    if (name === exports.AudioWorkletSourceURLPropertyName) {\n      this.privRecorder.setWorkletUrl(value);\n    } else {\n      throw new Error(\"Property '\" + name + \"' is not supported on Microphone.\");\n    }\n  }\n  getMicrophoneLabel() {\n    const defaultMicrophoneName = \"microphone\";\n    // If we did this already, return the value.\n    if (this.privMicrophoneLabel !== undefined) {\n      return Promise.resolve(this.privMicrophoneLabel);\n    }\n    // If the stream isn't currently running, we can't query devices because security.\n    if (this.privMediaStream === undefined || !this.privMediaStream.active) {\n      return Promise.resolve(defaultMicrophoneName);\n    }\n    // Setup a default\n    this.privMicrophoneLabel = defaultMicrophoneName;\n    // Get the id of the device running the audio track.\n    const microphoneDeviceId = this.privMediaStream.getTracks()[0].getSettings().deviceId;\n    // If the browser doesn't support getting the device ID, set a default and return.\n    if (undefined === microphoneDeviceId) {\n      return Promise.resolve(this.privMicrophoneLabel);\n    }\n    const deferred = new Exports_js_2.Deferred();\n    // Enumerate the media devices.\n    navigator.mediaDevices.enumerateDevices().then(devices => {\n      for (const device of devices) {\n        if (device.deviceId === microphoneDeviceId) {\n          // Found the device\n          this.privMicrophoneLabel = device.label;\n          break;\n        }\n      }\n      deferred.resolve(this.privMicrophoneLabel);\n    }, () => deferred.resolve(this.privMicrophoneLabel));\n    return deferred.promise;\n  }\n  listen(audioNodeId) {\n    return __awaiter(this, void 0, void 0, function* () {\n      yield this.turnOn();\n      const stream = new Exports_js_2.ChunkedArrayBufferStream(this.privOutputChunkSize, audioNodeId);\n      this.privStreams[audioNodeId] = stream;\n      try {\n        this.privRecorder.record(this.privContext, this.privMediaStream, stream);\n      } catch (error) {\n        this.onEvent(new Exports_js_2.AudioStreamNodeErrorEvent(this.privId, audioNodeId, error));\n        throw error;\n      }\n      const result = stream;\n      return result;\n    });\n  }\n  onEvent(event) {\n    this.privEvents.onEvent(event);\n    Exports_js_2.Events.instance.onEvent(event);\n  }\n  createAudioContext() {\n    if (!!this.privContext) {\n      return;\n    }\n    this.privContext = AudioStreamFormat_js_1.AudioStreamFormatImpl.getAudioContext(MicAudioSource.AUDIOFORMAT.samplesPerSec);\n  }\n  destroyAudioContext() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!this.privContext) {\n        return;\n      }\n      this.privRecorder.releaseMediaResources(this.privContext);\n      // This pattern brought to you by a bug in the TypeScript compiler where it\n      // confuses the (\"close\" in this.privContext) with this.privContext always being null as the alternate.\n      // https://github.com/Microsoft/TypeScript/issues/11498\n      let hasClose = false;\n      if (\"close\" in this.privContext) {\n        hasClose = true;\n      }\n      if (hasClose) {\n        if (!this.privIsClosing) {\n          // The audio context close may take enough time that the close is called twice\n          this.privIsClosing = true;\n          yield this.privContext.close();\n          this.privContext = null;\n          this.privIsClosing = false;\n        }\n      } else if (null !== this.privContext && this.privContext.state === \"running\") {\n        // Suspend actually takes a callback, but analogous to the\n        // resume method, it'll be only fired if suspend is called\n        // in a direct response to a user action. The later is not always\n        // the case, as TurnOff is also called, when we receive an\n        // end-of-speech message from the service. So, doing a best effort\n        // fire-and-forget here.\n        yield this.privContext.suspend();\n      }\n    });\n  }\n}\nexports.MicAudioSource = MicAudioSource;\nMicAudioSource.AUDIOFORMAT = AudioStreamFormat_js_1.AudioStreamFormat.getDefaultInputFormat();\n\n//# sourceMappingURL=MicAudioSource.js.map","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}