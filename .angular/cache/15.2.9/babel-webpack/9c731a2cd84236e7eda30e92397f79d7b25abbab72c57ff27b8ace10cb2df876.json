{"ast":null,"code":"\"use strict\";\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.ConversationTranscriptionServiceRecognizer = void 0;\nconst Exports_js_1 = require(\"../sdk/Exports.js\");\nconst Exports_js_2 = require(\"./Exports.js\");\n// eslint-disable-next-line max-classes-per-file\nclass ConversationTranscriptionServiceRecognizer extends Exports_js_2.ServiceRecognizerBase {\n  constructor(authentication, connectionFactory, audioSource, recognizerConfig, conversationTranscriber) {\n    super(authentication, connectionFactory, audioSource, recognizerConfig, conversationTranscriber);\n    this.privConversationTranscriber = conversationTranscriber;\n    this.setSpeakerDiarizationJson();\n  }\n  setSpeakerDiarizationJson() {\n    if (this.privEnableSpeakerId) {\n      const phraseDetection = this.privSpeechContext.getSection(\"phraseDetection\");\n      phraseDetection.mode = \"Conversation\";\n      const speakerDiarization = {};\n      speakerDiarization.mode = \"Anonymous\";\n      speakerDiarization.audioSessionId = this.privDiarizationSessionId;\n      speakerDiarization.audioOffsetMs = 0;\n      phraseDetection.speakerDiarization = speakerDiarization;\n      this.privSpeechContext.setSection(\"phraseDetection\", phraseDetection);\n    }\n  }\n  processTypeSpecificMessages(connectionMessage) {\n    return __awaiter(this, void 0, void 0, function* () {\n      let result;\n      const resultProps = new Exports_js_1.PropertyCollection();\n      resultProps.setProperty(Exports_js_1.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n      let processed = false;\n      switch (connectionMessage.path.toLowerCase()) {\n        case \"speech.hypothesis\":\n        case \"speech.fragment\":\n          const hypothesis = Exports_js_2.SpeechHypothesis.fromJSON(connectionMessage.textBody);\n          const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;\n          result = new Exports_js_1.ConversationTranscriptionResult(this.privRequestSession.requestId, Exports_js_1.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, undefined,\n          // Speaker Id\n          undefined, connectionMessage.textBody, resultProps);\n          this.privRequestSession.onHypothesis(offset);\n          const ev = new Exports_js_1.ConversationTranscriptionEventArgs(result, hypothesis.Duration, this.privRequestSession.sessionId);\n          if (!!this.privConversationTranscriber.transcribing) {\n            try {\n              this.privConversationTranscriber.transcribing(this.privConversationTranscriber, ev);\n              /* eslint-disable no-empty */\n            } catch (error) {\n              // Not going to let errors in the event handler\n              // trip things up.\n            }\n          }\n          processed = true;\n          break;\n        case \"speech.phrase\":\n          const simple = Exports_js_2.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody);\n          const resultReason = Exports_js_2.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus);\n          this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + simple.Offset + simple.Duration);\n          if (Exports_js_1.ResultReason.Canceled === resultReason) {\n            const cancelReason = Exports_js_2.EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);\n            const cancellationErrorCode = Exports_js_2.EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);\n            yield this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, Exports_js_2.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));\n          } else {\n            if (!(this.privRequestSession.isSpeechEnded && resultReason === Exports_js_1.ResultReason.NoMatch && simple.RecognitionStatus !== Exports_js_2.RecognitionStatus.InitialSilenceTimeout)) {\n              if (this.privRecognizerConfig.parameters.getProperty(Exports_js_2.OutputFormatPropertyName) === Exports_js_1.OutputFormat[Exports_js_1.OutputFormat.Simple]) {\n                result = new Exports_js_1.ConversationTranscriptionResult(this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simple.Offset + this.privRequestSession.currentTurnAudioOffset, simple.Language, simple.LanguageDetectionConfidence, simple.SpeakerId, undefined, connectionMessage.textBody, resultProps);\n              } else {\n                const detailed = Exports_js_2.DetailedSpeechPhrase.fromJSON(connectionMessage.textBody);\n                const totalOffset = detailed.Offset + this.privRequestSession.currentTurnAudioOffset;\n                const offsetCorrectedJson = detailed.getJsonWithCorrectedOffsets(totalOffset);\n                result = new Exports_js_1.ConversationTranscriptionResult(this.privRequestSession.requestId, resultReason, detailed.RecognitionStatus === Exports_js_2.RecognitionStatus.Success ? detailed.NBest[0].Display : undefined, detailed.Duration, totalOffset, detailed.Language, detailed.LanguageDetectionConfidence, simple.SpeakerId, undefined, offsetCorrectedJson, resultProps);\n              }\n              const event = new Exports_js_1.ConversationTranscriptionEventArgs(result, result.offset, this.privRequestSession.sessionId);\n              if (!!this.privConversationTranscriber.transcribed) {\n                try {\n                  this.privConversationTranscriber.transcribed(this.privConversationTranscriber, event);\n                  /* eslint-disable no-empty */\n                } catch (error) {\n                  // Not going to let errors in the event handler\n                  // trip things up.\n                }\n              }\n            }\n          }\n          processed = true;\n          break;\n        default:\n          break;\n      }\n      return processed;\n    });\n  }\n  // Cancels recognition.\n  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n    const properties = new Exports_js_1.PropertyCollection();\n    properties.setProperty(Exports_js_2.CancellationErrorCodePropertyName, Exports_js_1.CancellationErrorCode[errorCode]);\n    if (!!this.privConversationTranscriber.canceled) {\n      const cancelEvent = new Exports_js_1.ConversationTranscriptionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);\n      try {\n        this.privConversationTranscriber.canceled(this.privConversationTranscriber, cancelEvent);\n        /* eslint-disable no-empty */\n      } catch (_a) {}\n    }\n  }\n}\nexports.ConversationTranscriptionServiceRecognizer = ConversationTranscriptionServiceRecognizer;\n\n//# sourceMappingURL=ConversationTranscriptionServiceRecognizer.js.map","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}