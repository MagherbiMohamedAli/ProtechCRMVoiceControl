{"ast":null,"code":"\"use strict\";\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.SynthesisTurn = void 0;\nconst Exports_js_1 = require(\"../common/Exports.js\");\nconst AudioOutputStream_js_1 = require(\"../sdk/Audio/AudioOutputStream.js\");\nconst Exports_js_2 = require(\"../sdk/Exports.js\");\nconst SynthesisAudioMetadata_js_1 = require(\"./ServiceMessages/SynthesisAudioMetadata.js\");\nconst SynthesisEvents_js_1 = require(\"./SynthesisEvents.js\");\nclass SynthesisTurn {\n  constructor() {\n    this.privIsDisposed = false;\n    this.privIsSynthesizing = false;\n    this.privIsSynthesisEnded = false;\n    this.privBytesReceived = 0;\n    this.privInTurn = false;\n    this.privTextOffset = 0;\n    this.privNextSearchTextIndex = 0;\n    this.privSentenceOffset = 0;\n    this.privNextSearchSentenceIndex = 0;\n    this.privRequestId = Exports_js_1.createNoDashGuid();\n    this.privTurnDeferral = new Exports_js_1.Deferred();\n    // We're not in a turn, so resolve.\n    this.privTurnDeferral.resolve();\n  }\n  get requestId() {\n    return this.privRequestId;\n  }\n  get streamId() {\n    return this.privStreamId;\n  }\n  set streamId(value) {\n    this.privStreamId = value;\n  }\n  get audioOutputFormat() {\n    return this.privAudioOutputFormat;\n  }\n  set audioOutputFormat(format) {\n    this.privAudioOutputFormat = format;\n  }\n  get turnCompletionPromise() {\n    return this.privTurnDeferral.promise;\n  }\n  get isSynthesisEnded() {\n    return this.privIsSynthesisEnded;\n  }\n  get isSynthesizing() {\n    return this.privIsSynthesizing;\n  }\n  get currentTextOffset() {\n    return this.privTextOffset;\n  }\n  get currentSentenceOffset() {\n    return this.privSentenceOffset;\n  }\n  // The number of bytes received for current turn\n  get bytesReceived() {\n    return this.privBytesReceived;\n  }\n  get audioDuration() {\n    return this.privAudioDuration;\n  }\n  get extraProperties() {\n    if (!!this.privWebRTCSDP) {\n      const properties = new Exports_js_2.PropertyCollection();\n      properties.setProperty(Exports_js_2.PropertyId.TalkingAvatarService_WebRTC_SDP, this.privWebRTCSDP);\n      return properties;\n    }\n    return undefined;\n  }\n  getAllReceivedAudio() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!!this.privReceivedAudio) {\n        return Promise.resolve(this.privReceivedAudio);\n      }\n      if (!this.privIsSynthesisEnded) {\n        return null;\n      }\n      yield this.readAllAudioFromStream();\n      return Promise.resolve(this.privReceivedAudio);\n    });\n  }\n  getAllReceivedAudioWithHeader() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!!this.privReceivedAudioWithHeader) {\n        return this.privReceivedAudioWithHeader;\n      }\n      if (!this.privIsSynthesisEnded) {\n        return null;\n      }\n      if (this.audioOutputFormat.hasHeader) {\n        const audio = yield this.getAllReceivedAudio();\n        this.privReceivedAudioWithHeader = this.audioOutputFormat.addHeader(audio);\n        return this.privReceivedAudioWithHeader;\n      } else {\n        return this.getAllReceivedAudio();\n      }\n    });\n  }\n  startNewSynthesis(requestId, rawText, isSSML, audioDestination) {\n    this.privIsSynthesisEnded = false;\n    this.privIsSynthesizing = true;\n    this.privRequestId = requestId;\n    this.privRawText = rawText;\n    this.privIsSSML = isSSML;\n    this.privAudioOutputStream = new AudioOutputStream_js_1.PullAudioOutputStreamImpl();\n    this.privAudioOutputStream.format = this.privAudioOutputFormat;\n    this.privReceivedAudio = null;\n    this.privReceivedAudioWithHeader = null;\n    this.privBytesReceived = 0;\n    this.privTextOffset = 0;\n    this.privNextSearchTextIndex = 0;\n    this.privSentenceOffset = 0;\n    this.privNextSearchSentenceIndex = 0;\n    this.privPartialVisemeAnimation = \"\";\n    this.privWebRTCSDP = \"\";\n    if (audioDestination !== undefined) {\n      this.privTurnAudioDestination = audioDestination;\n      this.privTurnAudioDestination.format = this.privAudioOutputFormat;\n    }\n    this.onEvent(new SynthesisEvents_js_1.SynthesisTriggeredEvent(this.requestId, undefined, audioDestination === undefined ? undefined : audioDestination.id()));\n  }\n  onPreConnectionStart(authFetchEventId) {\n    this.privAuthFetchEventId = authFetchEventId;\n    this.onEvent(new SynthesisEvents_js_1.ConnectingToSynthesisServiceEvent(this.privRequestId, this.privAuthFetchEventId));\n  }\n  onAuthCompleted(isError) {\n    if (isError) {\n      this.onComplete();\n    }\n  }\n  onConnectionEstablishCompleted(statusCode) {\n    if (statusCode === 200) {\n      this.onEvent(new SynthesisEvents_js_1.SynthesisStartedEvent(this.requestId, this.privAuthFetchEventId));\n      this.privBytesReceived = 0;\n      return;\n    } else if (statusCode === 403) {\n      this.onComplete();\n    }\n  }\n  onServiceResponseMessage(responseJson) {\n    const response = JSON.parse(responseJson);\n    this.streamId = response.audio.streamId;\n  }\n  onServiceTurnEndResponse() {\n    this.privInTurn = false;\n    this.privTurnDeferral.resolve();\n    this.onComplete();\n  }\n  onServiceTurnStartResponse(responseJson) {\n    if (!!this.privTurnDeferral && !!this.privInTurn) {\n      // What? How are we starting a turn with another not done?\n      this.privTurnDeferral.reject(\"Another turn started before current completed.\");\n      // Avoid UnhandledPromiseRejection if privTurnDeferral is not being awaited\n      // eslint-disable-next-line @typescript-eslint/no-empty-function\n      this.privTurnDeferral.promise.then().catch(() => {});\n    }\n    this.privInTurn = true;\n    this.privTurnDeferral = new Exports_js_1.Deferred();\n    const response = JSON.parse(responseJson);\n    if (!!response.webrtc) {\n      this.privWebRTCSDP = response.webrtc.connectionString;\n    }\n  }\n  onAudioChunkReceived(data) {\n    if (this.isSynthesizing) {\n      this.privAudioOutputStream.write(data);\n      this.privBytesReceived += data.byteLength;\n      if (this.privTurnAudioDestination !== undefined) {\n        this.privTurnAudioDestination.write(data);\n      }\n    }\n  }\n  onTextBoundaryEvent(metadata) {\n    this.updateTextOffset(metadata.Data.text.Text, metadata.Type);\n  }\n  onVisemeMetadataReceived(metadata) {\n    if (metadata.Data.AnimationChunk !== undefined) {\n      this.privPartialVisemeAnimation += metadata.Data.AnimationChunk;\n    }\n  }\n  onSessionEnd(metadata) {\n    this.privAudioDuration = metadata.Data.Offset;\n  }\n  constructSynthesisResult() {\n    return __awaiter(this, void 0, void 0, function* () {\n      const audioBuffer = yield this.getAllReceivedAudioWithHeader();\n      return new Exports_js_2.SpeechSynthesisResult(this.requestId, Exports_js_2.ResultReason.SynthesizingAudioCompleted, audioBuffer, undefined, this.extraProperties, this.audioDuration);\n    });\n  }\n  dispose() {\n    if (!this.privIsDisposed) {\n      // we should have completed by now. If we did not its an unknown error.\n      this.privIsDisposed = true;\n    }\n  }\n  onStopSynthesizing() {\n    this.onComplete();\n  }\n  /**\n   * Gets the viseme animation string (merged from animation chunk), and clears the internal\n   * partial animation.\n   */\n  getAndClearVisemeAnimation() {\n    const animation = this.privPartialVisemeAnimation;\n    this.privPartialVisemeAnimation = \"\";\n    return animation;\n  }\n  onEvent(event) {\n    Exports_js_1.Events.instance.onEvent(event);\n  }\n  /**\n   * Check if the text is an XML(SSML) tag\n   * @param text\n   * @private\n   */\n  static isXmlTag(text) {\n    return text.length >= 2 && text[0] === \"<\" && text[text.length - 1] === \">\";\n  }\n  updateTextOffset(text, type) {\n    if (type === SynthesisAudioMetadata_js_1.MetadataType.WordBoundary) {\n      this.privTextOffset = this.privRawText.indexOf(text, this.privNextSearchTextIndex);\n      if (this.privTextOffset >= 0) {\n        this.privNextSearchTextIndex = this.privTextOffset + text.length;\n        if (this.privIsSSML) {\n          if (this.withinXmlTag(this.privTextOffset) && !SynthesisTurn.isXmlTag(text)) {\n            this.updateTextOffset(text, type);\n          }\n        }\n      }\n    } else {\n      this.privSentenceOffset = this.privRawText.indexOf(text, this.privNextSearchSentenceIndex);\n      if (this.privSentenceOffset >= 0) {\n        this.privNextSearchSentenceIndex = this.privSentenceOffset + text.length;\n        if (this.privIsSSML) {\n          if (this.withinXmlTag(this.privSentenceOffset) && !SynthesisTurn.isXmlTag(text)) {\n            this.updateTextOffset(text, type);\n          }\n        }\n      }\n    }\n  }\n  onComplete() {\n    if (this.privIsSynthesizing) {\n      this.privIsSynthesizing = false;\n      this.privIsSynthesisEnded = true;\n      this.privAudioOutputStream.close();\n      this.privInTurn = false;\n      if (this.privTurnAudioDestination !== undefined) {\n        this.privTurnAudioDestination.close();\n        this.privTurnAudioDestination = undefined;\n      }\n    }\n  }\n  readAllAudioFromStream() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privIsSynthesisEnded) {\n        this.privReceivedAudio = new ArrayBuffer(this.bytesReceived);\n        try {\n          yield this.privAudioOutputStream.read(this.privReceivedAudio);\n        } catch (e) {\n          this.privReceivedAudio = new ArrayBuffer(0);\n        }\n      }\n    });\n  }\n  /**\n   * Check if current idx is in XML(SSML) tag\n   * @param idx\n   * @private\n   */\n  withinXmlTag(idx) {\n    return this.privRawText.indexOf(\"<\", idx + 1) > this.privRawText.indexOf(\">\", idx + 1);\n  }\n}\nexports.SynthesisTurn = SynthesisTurn;\n\n//# sourceMappingURL=SynthesisTurn.js.map","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}