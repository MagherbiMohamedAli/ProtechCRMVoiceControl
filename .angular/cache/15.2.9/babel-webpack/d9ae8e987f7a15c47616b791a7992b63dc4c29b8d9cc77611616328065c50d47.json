{"ast":null,"code":"\"use strict\";\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.AvatarSynthesizer = void 0;\nconst SpeechSynthesisConnectionFactory_js_1 = require(\"../common.speech/SpeechSynthesisConnectionFactory.js\");\nconst Exports_js_1 = require(\"../common.speech/Exports.js\");\nconst Exports_js_2 = require(\"../common/Exports.js\");\nconst AudioOutputFormat_js_1 = require(\"./Audio/AudioOutputFormat.js\");\nconst Exports_js_3 = require(\"./Exports.js\");\nconst Contracts_js_1 = require(\"./Contracts.js\");\nconst Synthesizer_js_1 = require(\"./Synthesizer.js\");\n/**\n * Defines the avatar synthesizer.\n * @class AvatarSynthesizer\n * Added in version 1.33.0\n *\n * @experimental This feature is experimental and might change or have limited support.\n */\nclass AvatarSynthesizer extends Exports_js_3.Synthesizer {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {SpeechConfig} speechConfig - The speech config.\n   * @param {AvatarConfig} avatarConfig - The talking avatar config.\n   */\n  constructor(speechConfig, avatarConfig) {\n    super(speechConfig);\n    Contracts_js_1.Contracts.throwIfNullOrUndefined(avatarConfig, \"avatarConfig\");\n    this.privConnectionFactory = new SpeechSynthesisConnectionFactory_js_1.SpeechSynthesisConnectionFactory();\n    this.privAvatarConfig = avatarConfig;\n    this.implCommonSynthesizeSetup();\n  }\n  implCommonSynthesizeSetup() {\n    super.implCommonSynthesizeSetup();\n    // The service checks the audio format setting while it ignores it in avatar synthesis.\n    this.privAdapter.audioOutputFormat = AudioOutputFormat_js_1.AudioOutputFormatImpl.fromSpeechSynthesisOutputFormat(Exports_js_3.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm);\n  }\n  /**\n   * Starts the talking avatar session and establishes the WebRTC connection.\n   * @member AvatarSynthesizer.prototype.startAvatarAsync\n   * @function\n   * @public\n   * @param {AvatarWebRTCConnectionInfo} peerConnection - The peer connection.\n   * @returns {Promise<SynthesisResult>} The promise of the connection result.\n   */\n  startAvatarAsync(peerConnection) {\n    return __awaiter(this, void 0, void 0, function* () {\n      Contracts_js_1.Contracts.throwIfNullOrUndefined(peerConnection, \"peerConnection\");\n      this.privIceServers = peerConnection.getConfiguration().iceServers;\n      Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privIceServers, \"Ice servers must be set.\");\n      const iceGatheringDone = new Exports_js_2.Deferred();\n      // https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/icegatheringstatechange_event\n      peerConnection.onicegatheringstatechange = () => {\n        Exports_js_2.Events.instance.onEvent(new Exports_js_2.PlatformEvent(\"peer connection: ice gathering state: \" + peerConnection.iceGatheringState, Exports_js_2.EventType.Debug));\n        if (peerConnection.iceGatheringState === \"complete\") {\n          Exports_js_2.Events.instance.onEvent(new Exports_js_2.PlatformEvent(\"peer connection: ice gathering complete.\", Exports_js_2.EventType.Info));\n          iceGatheringDone.resolve();\n        }\n      };\n      const sdp = yield peerConnection.createOffer();\n      yield peerConnection.setLocalDescription(sdp);\n      yield iceGatheringDone.promise;\n      Exports_js_2.Events.instance.onEvent(new Exports_js_2.PlatformEvent(\"peer connection: got local SDP.\", Exports_js_2.EventType.Info));\n      this.privProperties.setProperty(Exports_js_3.PropertyId.TalkingAvatarService_WebRTC_SDP, JSON.stringify(peerConnection.localDescription));\n      const result = yield this.speak(\"\", false);\n      if (result.reason !== Exports_js_3.ResultReason.SynthesizingAudioCompleted) {\n        return new Exports_js_3.SynthesisResult(result.resultId, result.reason, result.errorDetails, result.properties);\n      }\n      const sdpAnswerString = atob(result.properties.getProperty(Exports_js_3.PropertyId.TalkingAvatarService_WebRTC_SDP));\n      const sdpAnswer = new RTCSessionDescription(JSON.parse(sdpAnswerString));\n      yield peerConnection.setRemoteDescription(sdpAnswer);\n      return new Exports_js_3.SynthesisResult(result.resultId, result.reason, undefined, result.properties);\n    });\n  }\n  /**\n   * Speaks plain text asynchronously. The rendered audio and video will be sent via the WebRTC connection.\n   * @member AvatarSynthesizer.prototype.speakTextAsync\n   * @function\n   * @public\n   * @param {string} text - The plain text to speak.\n   * @returns {Promise<SynthesisResult>} The promise of the synthesis result.\n   */\n  speakTextAsync(text) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const r = yield this.speak(text, false);\n      return new Exports_js_3.SynthesisResult(r.resultId, r.reason, r.errorDetails, r.properties);\n    });\n  }\n  /**\n   * Speaks SSML asynchronously. The rendered audio and video will be sent via the WebRTC connection.\n   * @member AvatarSynthesizer.prototype.speakSsmlAsync\n   * @function\n   * @public\n   * @param {string} ssml - The SSML text to speak.\n   * @returns {Promise<SynthesisResult>} The promise of the synthesis result.\n   */\n  speakSsmlAsync(ssml) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const r = yield this.speak(ssml, true);\n      return new Exports_js_3.SynthesisResult(r.resultId, r.reason, r.errorDetails, r.properties);\n    });\n  }\n  /**\n   * Speaks text asynchronously. The avatar will switch to idle state.\n   * @member AvatarSynthesizer.prototype.stopSpeakingAsync\n   * @function\n   * @public\n   * @returns {Promise<void>} The promise of the void result.\n   */\n  stopSpeakingAsync() {\n    return __awaiter(this, void 0, void 0, function* () {\n      while (this.synthesisRequestQueue.length() > 0) {\n        const request = yield this.synthesisRequestQueue.dequeue();\n        request.err(\"Synthesis is canceled by user.\");\n      }\n      return this.privAdapter.stopSpeaking();\n    });\n  }\n  /**\n   * Stops the talking avatar session and closes the WebRTC connection.\n   * For now, this is the same as close().\n   * You need to create a new AvatarSynthesizer instance to start a new session.\n   * @member AvatarSynthesizer.prototype.stopAvatarAsync\n   * @function\n   * @public\n   * @returns {Promise<void>} The promise of the void result.\n   */\n  stopAvatarAsync() {\n    return __awaiter(this, void 0, void 0, function* () {\n      Contracts_js_1.Contracts.throwIfDisposed(this.privDisposed);\n      return this.dispose(true);\n    });\n  }\n  /**\n   * Dispose of associated resources.\n   * @member AvatarSynthesizer.prototype.close\n   * @function\n   * @public\n   */\n  close() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privDisposed) {\n        return;\n      }\n      return this.dispose(true);\n    });\n  }\n  /**\n   * Gets the ICE servers. Internal use only.\n   */\n  get iceServers() {\n    return this.privIceServers;\n  }\n  // Creates the synthesis adapter\n  createSynthesisAdapter(authentication, connectionFactory, synthesizerConfig) {\n    return new Exports_js_1.AvatarSynthesisAdapter(authentication, connectionFactory, synthesizerConfig, this, this.privAvatarConfig);\n  }\n  createRestSynthesisAdapter(_authentication, _synthesizerConfig) {\n    return undefined;\n  }\n  createSynthesizerConfig(speechConfig) {\n    const config = super.createSynthesizerConfig(speechConfig);\n    config.avatarEnabled = true;\n    return config;\n  }\n  speak(text, isSSML) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const requestId = Exports_js_2.createNoDashGuid();\n      const deferredResult = new Exports_js_2.Deferred();\n      this.synthesisRequestQueue.enqueue(new Synthesizer_js_1.SynthesisRequest(requestId, text, isSSML, e => {\n        deferredResult.resolve(e);\n        this.privSynthesizing = false;\n        void this.adapterSpeak();\n      }, e => {\n        deferredResult.reject(e);\n        this.privSynthesizing = false;\n      }));\n      void this.adapterSpeak();\n      return deferredResult.promise;\n    });\n  }\n}\nexports.AvatarSynthesizer = AvatarSynthesizer;\n\n//# sourceMappingURL=AvatarSynthesizer.js.map","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}